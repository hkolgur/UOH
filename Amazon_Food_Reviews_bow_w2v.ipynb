{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Food_Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOD5jQNBv3KEYyhHisgorqd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkolgur/UOH/blob/main/Amazon_Food_Reviews_bow_w2v.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4eM75FhvyTN"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_1KXfZmv34Q"
      },
      "source": [
        "-Convert all the sentences into vectors to use the power of linear algebra\n",
        "To Convert Text to Vectors, one of the techinique we can use is Bag Of Words.\n",
        "\n",
        "Bag Of Words:\n",
        "\n",
        "1) Construct  a  dictionary of all the unique words that are present in the reviews/documents.(eg:{ This, chips , very , tasty ..})\n",
        "\n",
        "2) Construct a vector of d-dimension where d is the number of words present in corpus/dictionary that we created. Each word represents one dimention.\n",
        "\n",
        "3) For each review/document ,construct vector such that each cell represents the number times a word is repeted in that particular review/documnet . Eg if This is repeated twice we put 2 . If Tasty is present once we put 1.. other clells we leave it as zeroes\n",
        "\n",
        "4)Each vector (for each review is a sparse vector) because most of elements will be zerores.\n",
        "\n",
        "5) For given 2 vectors compute the norm ||v1-v2|| \n",
        "\n",
        "Drawbacks of BOW:\n",
        "\n",
        "If 2 reviews have same words with opposite menaing then the vectors sill have less distance between them and mislead to be simillar  \n",
        "Eg The food is very tasy and affordable vs This is very bad and affordable\n",
        "\n",
        "Boolean Bag Of Words:\n",
        "\n",
        " Instead of putting count of the occurances of words, we place 1 if word is present atleast from the corpus in the  review/document 0 otherwise\n",
        "The difference between Vectors v1, v2 is the # of differing words (|V2-V1| = sqrt*(# of differing words) \n",
        "\n",
        "Text Pre-processing:\n",
        "\n",
        "1) Filter stop words: Stop words do not convery much semantic meaning and hence can be ignored. Vectors will be meaningful and smaller if we remove stopwords\n",
        "(sometimes removing stopwords is not good because words like not is also a part of stop words, which completely changes meaning of the review/document)\n",
        "\n",
        "2) Convert all the text to lower case. Chips vs chips both coveys same meaning\n",
        "\n",
        "3)Stemming: eg. tasty,taste,taseful are form same base/root word taste. Hence we instead of having 3 vectors we can represent them in common form .(Porter vs Snowball stemmer) \n",
        "\n",
        "4)Lemmitization:  How to break sentence into wrods .It is language dependent and context dependent. (Eg New York cannot be broken it should be one word. Each symbol is represented as unique word in Japnese/other languages) . Lemitizers group New York into one word .\n",
        "\n",
        "5)Synoniyms like taste and delicious are same/simillar . But in BOW we consider them as different  as we dont consider semantic meaning of words . (Solution we use word2Vec) . \n",
        "\n",
        "Drawback of BOW is it does not take semantic meaning into consideration as we consider one dimension for every lemmitized word(uni-gram) \n",
        "\n",
        "One way to get around the problem is to use Bi-grams/Trigrams  (to get rid of lossing the opposite meaning by droping not as stop word) . This helps retain sequence information\n",
        "\n",
        "Bi-Gram - 2 consequtive words are represented as one dimension\n",
        "Tri-Gram - 3 consequtive words are represented as one dimension\n",
        "n-Grams- n consequtive words are represented as one dimension\n",
        "\n",
        "number of dimension in n-gram>Tri>Bigram>unigram\n",
        "\n",
        "TF-IDF (Term Frequency -Inverse document Freq)\n",
        "\n",
        "r,r2..rn n reviews with each review having w1,w2..wk words.\n",
        "TF(Wi,rj) = # Times Wi occurs in rj / Total words in rj \n",
        "Hence TF of any word lies between 0 and 1( Prob of finding wi in rj) \n",
        "\n",
        "IDF-Inverse Document Frequency . \n",
        "If r1,r2..rN are N reviews and Dc is the Document corpus that contains all the words from all the reviews.\n",
        "IDF(wi,Dc)= log( (Ni-Total number of documents)/ni -docs that contain wi)\n",
        "ni is always <=Ni because documents that contain wi cannot be more than total docs\n",
        "\n",
        "ni<=N => N/ni>=1 => log(N/ni)>=0 . Idf is > 0 for any word.\n",
        "as ni increases log(N/ni) decreases . so if a word is more frequent then it has lower IDF value ( eg. The occurs in almost all documents)\n",
        "\n",
        "Combine TF and IDF\n",
        "\n",
        "For a particular word wj in a particular reveiw ri \n",
        "TF-IDF = Term Freq(word wj in review ri) * IDF(word wj in doc corpus Dc) \n",
        "\n",
        "TF-IDF gives more importance to the rare words. \n",
        "\n",
        "Drawback it still do not take semantic meaning into consideration. Eg. Tasty and delicious are same but it doesnt consider.\n",
        "\n",
        "why use log? in TF-IDF - no strong theory around it but used as a hack\n",
        "The frequency of words in english language follows a power law distribution(almsot) Hence taking we can conver it to Gausian dist with Box cox transformation.(core ideas of box cox is to take log or r.v) \n",
        "\n",
        "Other reason is if we use N/ni -> The gets almsot 1 and rare word that is one in 1000 gets 1000/1 = 1000 . The gap is very large instead if we take log it will be 6.9 instead of 1000 . This help to reduce the impact of IDF value which will dominate otherwise and TF will not have essence in rare words\n",
        "\n",
        "\n",
        "\n",
        "Word2Vec:\n",
        "\n",
        "BOW and TF-IDF do not take semantic meaning into consideration.\n",
        "Takes a word and converts into a vector. if 2 words are given it gives 2 vectors in such a way the relationship between words are preserved.\n",
        "Eg. Man is opposite gender of Women. King is opposite gender of Queen\n",
        "Now V-man - V-women is parallel to V-king -V-QUeen\n",
        "\n",
        "Core Intuition of word2Vec is that vector for a word w3 takes into consideration of the words in its Neighbourhood like w1,w2, w4,w5. If Neighbourhood of wi is simillar to word wj then the vecotros of these 2 words vi and vj will be very simillar  \n",
        "\n",
        "Give large text documents (eg 500k reviews) to w2Vec and train. It then generates vectors for each word in review to predict.\n",
        "\n",
        "Average WOrd2Vec\n",
        "w2vec converts a word to vector but bow to convert a sentence into a vector? One way is to take average w2vec of each word in the review.\n",
        "ie sum all the vectros of each word and divide by the number of words in that reviw to get average of the vectors\n",
        "\n",
        "TF-IDF weighted word2vec:\n",
        "\n",
        "for Review r1 first compute the TF-IDF for each word say t1, t2,t3... , Also compute the word2Vec of each word w2v(w1),w2v(w2),...\n",
        "Now mulitply each (t1*w2v(w1) + t2*w2v(t2) ..)/(t1 + t2...)  . Here if t1=t2=..=1 ie all are 1 then it is equvilant to average word2vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyRn-lteurzb",
        "outputId": "7d6e0a3f-3167-485d-b281-3d1870b50757"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzcDom2IxDbP"
      },
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhEDhAMixE74"
      },
      "source": [
        "con=sqlite3.connect('/content/drive/MyDrive/UOH/AmazonReviews/database.sqlite')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP1uplwP4zY7"
      },
      "source": [
        "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 LIMIT 5000\"\"\",con) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "TgywMs4__NNq",
        "outputId": "93d2b5f3-6d3c-4696-d98b-e4b93a31bac2"
      },
      "source": [
        "filtered_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDi7NRgV_OK5",
        "outputId": "5d9eca45-038f-49b8-93e3-563388099192"
      },
      "source": [
        "print(sum(filtered_data['Score']<3))# count of Negative reviews\n",
        "print(sum(filtered_data['Score']>3)) # count of Positive reviews"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "813\n",
            "4187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC_ptU6tcJ47"
      },
      "source": [
        "#Function to determine if the review is positive or negative based on the Score.\n",
        "def positive_Negative(x):\n",
        "  if x<3:\n",
        "    return 0\n",
        "  return 1\n",
        "\n",
        "#Create a new column Sentiment which is derived based on the values of Score column\n",
        "filtered_data['Sentiment']=filtered_data.apply(lambda row: positive_Negative(row['Score']),axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "On8bMWw4iwd0",
        "outputId": "17f91c28-a5a5-4926-a2f1-d515c6d95dd3"
      },
      "source": [
        "filtered_data[['Score','Sentiment']]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Score  Sentiment\n",
              "0         5          1\n",
              "1         1          0\n",
              "2         4          1\n",
              "3         2          0\n",
              "4         5          1\n",
              "...     ...        ...\n",
              "4995      2          0\n",
              "4996      4          1\n",
              "4997      5          1\n",
              "4998      2          0\n",
              "4999      1          0\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co_xKf-Vn6dC"
      },
      "source": [
        "#Drop the Score column\n",
        "filtered_data.drop(columns='Score',inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "o_k_hFT9oj7o",
        "outputId": "a9163b7e-3b84-453c-870a-2e43f1c9a412"
      },
      "source": [
        "filtered_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ...                                               Text Sentiment\n",
              "0   1  B001E4KFG0  ...  I have bought several of the Vitality canned d...         1\n",
              "1   2  B00813GRG4  ...  Product arrived labeled as Jumbo Salted Peanut...         0\n",
              "2   3  B000LQOCH0  ...  This is a confection that has been around a fe...         1\n",
              "3   4  B000UA0QIQ  ...  If you are looking for the secret ingredient i...         0\n",
              "4   5  B006K2ZZ7K  ...  Great taffy at a great price.  There was a wid...         1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xucPX9sAonMK",
        "outputId": "b85a285d-11fd-427a-f89c-c9dd39ee0b4e"
      },
      "source": [
        "filtered_data['Text']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I have bought several of the Vitality canned d...\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...\n",
              "2       This is a confection that has been around a fe...\n",
              "3       If you are looking for the secret ingredient i...\n",
              "4       Great taffy at a great price.  There was a wid...\n",
              "                              ...                        \n",
              "4995    My baby didn't seem into these dinners, so I t...\n",
              "4996    This is great!  Organic baby food options - de...\n",
              "4997    My little guy loves to try new foods..so this ...\n",
              "4998    We ordered the Earth's best 2nd dinner variety...\n",
              "4999    My baby loves this food.  At whole foods they ...\n",
              "Name: Text, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whl3mMjqGuPE"
      },
      "source": [
        "# select specific columns\n",
        "display = pd.read_sql_query(\"\"\"\n",
        "SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*)\n",
        "FROM Reviews\n",
        "GROUP BY UserId\n",
        "HAVING COUNT(*)>1\n",
        "\"\"\", con)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiHXzuzYMUeT",
        "outputId": "42214a70-748d-45fa-8379-38506491e1c8"
      },
      "source": [
        "#Check the  maximum number of reviews given by any person \n",
        "display['COUNT(*)'].max()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "8NyKxBGJJCU9",
        "outputId": "eea5c7ae-726e-4c1d-d67c-eefa573a1220"
      },
      "source": [
        "#Lets check the userid of the person who gave maximum number of reviews\n",
        "display[display['COUNT(*)']==448]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>Time</th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "      <th>COUNT(*)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57359</th>\n",
              "      <td>A3OXHLG6DIBRW8</td>\n",
              "      <td>B005K4Q68Q</td>\n",
              "      <td>C. F. Hill \"CFH\"</td>\n",
              "      <td>1321401600</td>\n",
              "      <td>5</td>\n",
              "      <td>These Grove Square Hot Cocoa flavors are by fa...</td>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               UserId  ... COUNT(*)\n",
              "57359  A3OXHLG6DIBRW8  ...      448\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "nQEFpNuDJk2r",
        "outputId": "80d0c116-2421-4f9a-97c4-ba0089c7b4ca"
      },
      "source": [
        "filtered_data[filtered_data['UserId']=='A3OXHLG6DIBRW8']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>370</td>\n",
              "      <td>B002O3VHXU</td>\n",
              "      <td>A3OXHLG6DIBRW8</td>\n",
              "      <td>C. F. Hill \"CFH\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1282176000</td>\n",
              "      <td>Very Smooth Coffee - Highly Recommended</td>\n",
              "      <td>Green Mountain \"Nantucket Blend\" K-Cups make a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>814</td>\n",
              "      <td>B004ET7MG8</td>\n",
              "      <td>A3OXHLG6DIBRW8</td>\n",
              "      <td>C. F. Hill \"CFH\"</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1272240000</td>\n",
              "      <td>Odd Fake Flavor - Not Recommended</td>\n",
              "      <td>Trident \"Strawberry Twist\" sugarless gum is ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3034</th>\n",
              "      <td>3307</td>\n",
              "      <td>B005K4Q1VI</td>\n",
              "      <td>A3OXHLG6DIBRW8</td>\n",
              "      <td>C. F. Hill \"CFH\"</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>1321401600</td>\n",
              "      <td>Really Good Hot Cocoa - Highly Recommended</td>\n",
              "      <td>These Grove Square Hot Cocoa flavors are by fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>3417</td>\n",
              "      <td>B005K4Q1VI</td>\n",
              "      <td>A3OXHLG6DIBRW8</td>\n",
              "      <td>C. F. Hill \"CFH\"</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1321401600</td>\n",
              "      <td>Really Good Hot Cocoa - Highly Recommended</td>\n",
              "      <td>These Grove Square Hot Cocoa flavors are by fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3613</th>\n",
              "      <td>3927</td>\n",
              "      <td>B000VSDFRG</td>\n",
              "      <td>A3OXHLG6DIBRW8</td>\n",
              "      <td>C. F. Hill \"CFH\"</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1237161600</td>\n",
              "      <td>Great Diabetic Friendly Candy - Highly Recomme...</td>\n",
              "      <td>Hershey \"Sugar Free Caramel Filled Chocolates\"...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  ... Sentiment\n",
              "338    370  ...         1\n",
              "753    814  ...         0\n",
              "3034  3307  ...         1\n",
              "3139  3417  ...         1\n",
              "3613  3927  ...         1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MiT6qB4N-4P"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0updKHOEOd"
      },
      "source": [
        "#### Lets review the products reviewed by user AR5J8UI46CURR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zgt1vS4Kp9Y"
      },
      "source": [
        "display=pd.read_sql_query(\"\"\"select * from Reviews where Userid=='AR5J8UI46CURR'\"\"\",con)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "KqbWmKEYOc6e",
        "outputId": "f8f13960-99bc-4146-9ada-3d720fe92760"
      },
      "source": [
        "display.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>73791</td>\n",
              "      <td>B000HDOPZG</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>78445</td>\n",
              "      <td>B000HDL1RQ</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>138277</td>\n",
              "      <td>B000HDOPYM</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>138317</td>\n",
              "      <td>B000HDOPYC</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155049</td>\n",
              "      <td>B000PAQ75C</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ...                                               Text\n",
              "0   73791  ...  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...\n",
              "1   78445  ...  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...\n",
              "2  138277  ...  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...\n",
              "3  138317  ...  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...\n",
              "4  155049  ...  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFaCnBMgOpW2"
      },
      "source": [
        "#### Observation: For this particular user we observe that the score is same for all producta and even the time stamp of review is same. when the User Rated one item, the review might have been mapped to multiple items in that particular brand/group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxyjxyqzPM0Q"
      },
      "source": [
        "#### Lets Sort the data and remove duplicates . we can define the critera of a duplicate if it has same \"UserId\",\"ProfileName\",\"Time\",\"Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BQyAjzsO8rk"
      },
      "source": [
        "#Sorting data according to ProductId in ascending order\n",
        "sorted_data=filtered_data.sort_values(by='ProductId',kind='quicksort',ascending=True,axis=0,na_position='last',inplace=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szJHE-YkRcjF",
        "outputId": "0d00eb49-b166-49a3-c973-02f0256b3645"
      },
      "source": [
        "sorted_data.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0HnKvROQiJf"
      },
      "source": [
        "#Deduplication of entries\n",
        "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},inplace=False,keep='first')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adL7ivA4RUKK",
        "outputId": "25f442f2-351b-49d1-d87f-51f469a6e02d"
      },
      "source": [
        "final.shape "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4986, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djv7ryItRVFn",
        "outputId": "abbc193a-a532-4fd8-fab7-43b781e72d2c"
      },
      "source": [
        "#Checking to see how much % of data still remains\n",
        "(final.shape[0]/sorted_data.shape[0])*100"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvy0wUnGR6vD"
      },
      "source": [
        "#select the rows that have helpfulness Numerator less than or= denominator ( if > it is an error)\n",
        "\n",
        "final=final[final['HelpfulnessNumerator']<=final['HelpfulnessDenominator']]\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWZT7SnXTLk3",
        "outputId": "ce70bb39-f793-49fd-cafe-603257b54b26"
      },
      "source": [
        "#lets see the number of entries left\n",
        "print(final.shape)\n",
        "#lets see the number of entries with positive and Negative sentiment\n",
        "print(final['Sentiment'].value_counts())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4986, 10)\n",
            "1    4178\n",
            "0     808\n",
            "Name: Sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEBrJAD7UGMN"
      },
      "source": [
        "# Text Pre-Processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "PWWqanbPUfSd",
        "outputId": "7ab9eb85-5752-4fdc-fb23-ac75a5f603dc"
      },
      "source": [
        "# Lets view first review \n",
        "final['Text'].values[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Why is this $[...] when the same product is available for $[...] here?<br />http://www.amazon.com/VICTOR-FLY-MAGNET-BAIT-REFILL/dp/B00004RBDY<br /><br />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but only right nearby.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ko-fvLJUs54"
      },
      "source": [
        "#### Observation: Above we see there are lot of html tags present as part of the revoew . we have to clean it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJvU8GrTggn",
        "outputId": "d80fa4f7-8add-48b0-dada-fe04a703bcdc"
      },
      "source": [
        "# printing some random reviews\n",
        "sent_0 = final['Text'].values[0]\n",
        "print(sent_0)\n",
        "print(\"=\"*50)\n",
        "\n",
        "sent_1000 = final['Text'].values[1000]\n",
        "print(sent_1000)\n",
        "print(\"=\"*50)\n",
        "\n",
        "sent_1500 = final['Text'].values[1500]\n",
        "print(sent_1500)\n",
        "print(\"=\"*50)\n",
        "\n",
        "sent_4900 = final['Text'].values[4900]\n",
        "print(sent_4900)\n",
        "print(\"=\"*50)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why is this $[...] when the same product is available for $[...] here?<br />http://www.amazon.com/VICTOR-FLY-MAGNET-BAIT-REFILL/dp/B00004RBDY<br /><br />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but only right nearby.\n",
            "==================================================\n",
            "I recently tried this flavor/brand and was surprised at how delicious these chips are.  The best thing was that there were a lot of \"brown\" chips in the bsg (my favorite), so I bought some more through amazon and shared with family and friends.  I am a little disappointed that there are not, so far, very many brown chips in these bags, but the flavor is still very good.  I like them better than the yogurt and green onion flavor because they do not seem to be as salty, and the onion flavor is better.  If you haven't eaten Kettle chips before, I recommend that you try a bag before buying bulk.  They are thicker and crunchier than Lays but just as fresh out of the bag.\n",
            "==================================================\n",
            "Wow.  So far, two two-star reviews.  One obviously had no idea what they were ordering; the other wants crispy cookies.  Hey, I'm sorry; but these reviews do nobody any good beyond reminding us to look  before ordering.<br /><br />These are chocolate-oatmeal cookies.  If you don't like that combination, don't order this type of cookie.  I find the combo quite nice, really.  The oatmeal sort of \"calms\" the rich chocolate flavor and gives the cookie sort of a coconut-type consistency.  Now let's also remember that tastes differ; so, I've given my opinion.<br /><br />Then, these are soft, chewy cookies -- as advertised.  They are not \"crispy\" cookies, or the blurb would say \"crispy,\" rather than \"chewy.\"  I happen to like raw cookie dough; however, I don't see where these taste like raw cookie dough.  Both are soft, however, so is this the confusion?  And, yes, they stick together.  Soft cookies tend to do that.  They aren't individually wrapped, which would add to the cost.  Oh yeah, chocolate chip cookies tend to be somewhat sweet.<br /><br />So, if you want something hard and crisp, I suggest Nabiso's Ginger Snaps.  If you want a cookie that's soft, chewy and tastes like a combination of chocolate and oatmeal, give these a try.  I'm here to place my second order.\n",
            "==================================================\n",
            "love to order my coffee on amazon.  easy and shows up quickly.<br />This k cup is great coffee.  dcaf is very good as well\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlTaffWrwKAy",
        "outputId": "ca84e5e0-4a3d-4ec1-aaa9-13d8ff40a4fd"
      },
      "source": [
        "# remove urls from text python: https://stackoverflow.com/a/40823105/4084039\n",
        "sent_0 = re.sub(r\"http\\S+\", \"\", sent_0)\n",
        "sent_1000 = re.sub(r\"http\\S+\", \"\", sent_1000)\n",
        "sent_1500= re.sub(r\"http\\S+\", \"\", sent_1500)\n",
        "sent_4900 = re.sub(r\"http\\S+\", \"\", sent_4900)\n",
        "\n",
        "print(sent_0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why is this $[...] when the same product is available for $[...] here?<br /> /><br />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but only right nearby.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVo7behl3uX5",
        "outputId": "33eca0f0-28ba-4737-a7f2-571e44f14a0a"
      },
      "source": [
        "soup=BeautifulSoup(sent_0,'lxml')\n",
        "text=soup.get_text()\n",
        "print(text)\n",
        "print(\"=\"*50)\n",
        "\n",
        "soup=BeautifulSoup(sent_1000,'lxml')\n",
        "text=soup.get_text()\n",
        "print(text)\n",
        "print(\"=\"*50)\n",
        "\n",
        "soup=BeautifulSoup(sent_1500,'lxml')\n",
        "text=soup.get_text()\n",
        "print(text)\n",
        "print(\"=\"*50)\n",
        "\n",
        "soup = BeautifulSoup(sent_4900, 'lxml')\n",
        "text = soup.get_text()\n",
        "print(text)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why is this $[...] when the same product is available for $[...] here? />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but only right nearby.\n",
            "==================================================\n",
            "I recently tried this flavor/brand and was surprised at how delicious these chips are.  The best thing was that there were a lot of \"brown\" chips in the bsg (my favorite), so I bought some more through amazon and shared with family and friends.  I am a little disappointed that there are not, so far, very many brown chips in these bags, but the flavor is still very good.  I like them better than the yogurt and green onion flavor because they do not seem to be as salty, and the onion flavor is better.  If you haven't eaten Kettle chips before, I recommend that you try a bag before buying bulk.  They are thicker and crunchier than Lays but just as fresh out of the bag.\n",
            "==================================================\n",
            "Wow.  So far, two two-star reviews.  One obviously had no idea what they were ordering; the other wants crispy cookies.  Hey, I'm sorry; but these reviews do nobody any good beyond reminding us to look  before ordering.These are chocolate-oatmeal cookies.  If you don't like that combination, don't order this type of cookie.  I find the combo quite nice, really.  The oatmeal sort of \"calms\" the rich chocolate flavor and gives the cookie sort of a coconut-type consistency.  Now let's also remember that tastes differ; so, I've given my opinion.Then, these are soft, chewy cookies -- as advertised.  They are not \"crispy\" cookies, or the blurb would say \"crispy,\" rather than \"chewy.\"  I happen to like raw cookie dough; however, I don't see where these taste like raw cookie dough.  Both are soft, however, so is this the confusion?  And, yes, they stick together.  Soft cookies tend to do that.  They aren't individually wrapped, which would add to the cost.  Oh yeah, chocolate chip cookies tend to be somewhat sweet.So, if you want something hard and crisp, I suggest Nabiso's Ginger Snaps.  If you want a cookie that's soft, chewy and tastes like a combination of chocolate and oatmeal, give these a try.  I'm here to place my second order.\n",
            "==================================================\n",
            "love to order my coffee on amazon.  easy and shows up quickly.This k cup is great coffee.  dcaf is very good as well\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHKnMrGB8na-"
      },
      "source": [
        "# Method to remove abbrevations and substitute with full words\n",
        "#Eg: change can't to can not .\n",
        "\n",
        "def substitutions(phrase):\n",
        "  # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vikGfpBe-ZAh",
        "outputId": "3b00f697-4e4d-426b-8b0e-ee073d167e66"
      },
      "source": [
        "sent_1500=substitutions(sent_1500)\n",
        "print(sent_1500)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wow.  So far, two two-star reviews.  One obviously had no idea what they were ordering; the other wants crispy cookies.  Hey, I am sorry; but these reviews do nobody any good beyond reminding us to look  before ordering.<br /><br />These are chocolate-oatmeal cookies.  If you do not like that combination, do not order this type of cookie.  I find the combo quite nice, really.  The oatmeal sort of \"calms\" the rich chocolate flavor and gives the cookie sort of a coconut-type consistency.  Now let is also remember that tastes differ; so, I have given my opinion.<br /><br />Then, these are soft, chewy cookies -- as advertised.  They are not \"crispy\" cookies, or the blurb would say \"crispy,\" rather than \"chewy.\"  I happen to like raw cookie dough; however, I do not see where these taste like raw cookie dough.  Both are soft, however, so is this the confusion?  And, yes, they stick together.  Soft cookies tend to do that.  They are not individually wrapped, which would add to the cost.  Oh yeah, chocolate chip cookies tend to be somewhat sweet.<br /><br />So, if you want something hard and crisp, I suggest Nabiso is Ginger Snaps.  If you want a cookie that is soft, chewy and tastes like a combination of chocolate and oatmeal, give these a try.  I am here to place my second order.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdydwEDYBAOX",
        "outputId": "241c434a-3727-4393-e1b6-609d282f84bf"
      },
      "source": [
        "#remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
        "sent_0 = re.sub(\"\\S*\\d\\S*\", \"\", sent_0).strip()\n",
        "print(sent_0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why is this $[...] when the same product is available for $[...] here?<br /> /><br />The Victor  and  traps are unreal, of course -- total fly genocide. Pretty stinky, but only right nearby.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7J0IMKQBrDj",
        "outputId": "b2a70119-9c35-4de6-a3a7-5b5418bc6a62"
      },
      "source": [
        "#remove spacial character: https://stackoverflow.com/a/5843547/4084039\n",
        "sent_1500 = re.sub('[^A-Za-z0-9]+', ' ', sent_1500)\n",
        "print(sent_1500)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wow So far two two star reviews One obviously had no idea what they were ordering the other wants crispy cookies Hey I am sorry but these reviews do nobody any good beyond reminding us to look before ordering br br These are chocolate oatmeal cookies If you do not like that combination do not order this type of cookie I find the combo quite nice really The oatmeal sort of calms the rich chocolate flavor and gives the cookie sort of a coconut type consistency Now let is also remember that tastes differ so I have given my opinion br br Then these are soft chewy cookies as advertised They are not crispy cookies or the blurb would say crispy rather than chewy I happen to like raw cookie dough however I do not see where these taste like raw cookie dough Both are soft however so is this the confusion And yes they stick together Soft cookies tend to do that They are not individually wrapped which would add to the cost Oh yeah chocolate chip cookies tend to be somewhat sweet br br So if you want something hard and crisp I suggest Nabiso is Ginger Snaps If you want a cookie that is soft chewy and tastes like a combination of chocolate and oatmeal give these a try I am here to place my second order \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B77MUyECHo8"
      },
      "source": [
        "# https://gist.github.com/sebleier/554280\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
        "# we are including them into stop words list\n",
        "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "CuqHBY8vFAGJ",
        "outputId": "a6476ade-1d72-4d61-b287-fb1f5b9679fd"
      },
      "source": [
        "#split the sentence with space , convert each word to lower case ,remove stop words and then combine the sentence\n",
        "' '.join(e.lower() for e in sent_1500.split() if e.lower() not in stopwords)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wow far two two star reviews one obviously no idea ordering wants crispy cookies hey sorry reviews nobody good beyond reminding us look ordering chocolate oatmeal cookies not like combination not order type cookie find combo quite nice really oatmeal sort calms rich chocolate flavor gives cookie sort coconut type consistency let also remember tastes differ given opinion soft chewy cookies advertised not crispy cookies blurb would say crispy rather chewy happen like raw cookie dough however not see taste like raw cookie dough soft however confusion yes stick together soft cookies tend not individually wrapped would add cost oh yeah chocolate chip cookies tend somewhat sweet want something hard crisp suggest nabiso ginger snaps want cookie soft chewy tastes like combination chocolate oatmeal give try place second order'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYmN-uIoCgnN",
        "outputId": "3b6daedc-66ae-4431-d9da-90af86c5fcd0"
      },
      "source": [
        "# Combining all the above  \n",
        "\n",
        "from tqdm import tqdm\n",
        "# tqdm is for printing the status bar\n",
        "\n",
        "preprocessed_reviews = []\n",
        "\n",
        "for sentance in tqdm(final['Text'].values):\n",
        "  sentance=re.sub('http\\S+','',sentance)\n",
        "  sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "  sentence=substitutions(sentance)\n",
        "  sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "  sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "\n",
        "  sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "  preprocessed_reviews.append(sentance.strip())\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4986/4986 [00:01<00:00, 2762.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2cVPGXYG4lu",
        "outputId": "1a59abb6-4c87-4e4d-97ab-2963aba3e2cb"
      },
      "source": [
        "preprocessed_reviews[0:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['product available victor traps unreal course total fly genocide pretty stinky right nearby',\n",
              " 'used victor fly bait seasons beat great product',\n",
              " 'received shipment could hardly wait try product love slickers call instead stickers removed easily daughter designed signs printed reverse use car windows printed beautifully print shop program going lot fun product windows everywhere surfaces like tv screens computer monitors',\n",
              " 'really good idea final product outstanding use decals car window everybody asks bought decals made two thumbs',\n",
              " 'glad cocker standard poodle puppy loves stuff trust brand superior nutrition compare labels previous feed pedigree mostly corn little dude healthy happy high energy glossy coat also superior nutrition produces smaller compact stools',\n",
              " 'using food months find excellent fact two dogs coton de tulear standard poodle puppy love food thriving coats excellent condition overall structure perfect good tasting dog good good deal owner around best food ever used excellent',\n",
              " 'nine cats crazy kibbles last thing want cat food cats hate buying',\n",
              " 'shipped day ordered arrived within days live opposite coast made order arrived nicely packaged price got lbs oz biscotti weighed kitchen scale cut big pieces add shipping handling comes little per piece approximately local bakery charges per biscotti guess going price homemade biscotti days flavor almondy hardness perfect biscotti hard crunchy not hard eat without dunking biscotti biscotti eaten dunked coffee tea cocoa dunked mine chai tea tastes great biscotti not fall apart dunked like almond flavor wish came anise flavor favorite biscotti flavor',\n",
              " 'mix probably not something would want use everyday new enough different enough something special add summertime recipe want reward something fun fruity fill bill quickly easily no aftertaste often associated diet drinks highly recommend',\n",
              " 'description product disceptive product represented powder not powder granule nothing shredded coconut even dissolve high speed commercial blender unless using product manufacture dark chocolate coated coconut patty useless intention use additive healthy shake ended ruining shake resort chewing undissolved tasteless coconut pieces rather drinking shake additionally way product packaged no protective cardboard preventing slashing top package box opened could rated product zero stars would redeeming quality rather inexpensive gave one package away free patient loves coconut gave back two days later complaining terrible']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPA8S0KwGAbD"
      },
      "source": [
        "# Featurization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibMtLezLGIxF"
      },
      "source": [
        "# BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFRtClZfElO5",
        "outputId": "74a0ccb4-d184-4d89-d00f-bdf7390a9d26"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#BoW\n",
        "count_vect = CountVectorizer() \n",
        "count_vect.fit(preprocessed_reviews)\n",
        "print(\"some feature names \", count_vect.get_feature_names()[:10])\n",
        "print('='*50)\n",
        "\n",
        "final_counts = count_vect.transform(preprocessed_reviews)\n",
        "print(\"the type of count vectorizer \",type(final_counts))\n",
        "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
        "print(\"the number of unique words \", final_counts.get_shape()[1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "some feature names  ['aa', 'aahhhs', 'aback', 'abandon', 'abates', 'abbott', 'abby', 'abdominal', 'abiding', 'ability']\n",
            "==================================================\n",
            "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text BOW vectorizer  (4986, 12974)\n",
            "the number of unique words  12974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdaaaUwZVY_i",
        "outputId": "8a728984-4f18-4c39-e43d-43d880ce58f4"
      },
      "source": [
        "# size of the vocabulary \n",
        "len(count_vect.vocabulary_)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hh9UiUJW0WP"
      },
      "source": [
        "# Bi-Grams and n-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81BVnc6GVeVy",
        "outputId": "0bd98c19-d3cd-4e8d-cf55-94d9eacc25bc"
      },
      "source": [
        "count_vect=CountVectorizer(preprocessed_reviews,ngram_range=(1,2),min_df=10, max_features=5000)\n",
        "count_vect.fit(preprocessed_reviews)  \n",
        "# size of the vocabulary \n",
        "print(\"Vocabulary Length:\",len(count_vect.vocabulary_))\n",
        "\n",
        "final_bigram_counts=count_vect.transform(preprocessed_reviews)\n",
        "print(\"the type of count vectorizer \",type(final_bigram_counts))\n",
        "print(\"the shape of out text BOW vectorizer \",final_bigram_counts.get_shape())\n",
        "print(\"the number of unique words including both unigrams and bigrams \", final_bigram_counts.get_shape()[1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Length: 3029\n",
            "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text BOW vectorizer  (4986, 3029)\n",
            "the number of unique words including both unigrams and bigrams  3029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1mjhHMGZTQU",
        "outputId": "2d0e0b43-904f-4301-ad2b-4cae59db7319"
      },
      "source": [
        "# Tri-Grams\n",
        "count_vect=CountVectorizer(preprocessed_reviews,ngram_range=(1,3),min_df=10, max_features=5000)\n",
        "count_vect.fit(preprocessed_reviews)  "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                input=['product available victor traps unreal course total fly '\n",
              "                       'genocide pretty stinky right nearby',\n",
              "                       'used victor fly bait seasons beat great product',\n",
              "                       'received shipment could hardly wait try product love '\n",
              "                       'slickers call instead stickers removed easily daughter '\n",
              "                       'designed...\n",
              "                       'like bean skins get paste put ice cream fill pasteries '\n",
              "                       'stuff mochi cakes',\n",
              "                       'good beans find grocery stores live ordered retailer '\n",
              "                       'no problems',\n",
              "                       'not good yummy smell like cloves cooking taste little '\n",
              "                       'sweet', ...],\n",
              "                lowercase=True, max_df=1.0, max_features=5000, min_df=10,\n",
              "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw2HC2NcZXqS",
        "outputId": "8b33bacb-7a38-4d9c-cca9-dc86db8a1803"
      },
      "source": [
        "print(\"Vocabulary Length:\",count_vect.vocabulary_)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Length: {'product': 2106, 'available': 135, 'course': 592, 'total': 2784, 'pretty': 2080, 'right': 2267, 'nearby': 1730, 'used': 2864, 'beat': 188, 'great': 1151, 'great product': 1163, 'received': 2200, 'shipment': 2400, 'could': 579, 'hardly': 1225, 'wait': 2907, 'try': 2816, 'love': 1552, 'call': 348, 'instead': 1351, 'easily': 775, 'daughter': 644, 'designed': 685, 'use': 2859, 'car': 367, 'windows': 2982, 'shop': 2406, 'program': 2117, 'going': 1099, 'lot': 1550, 'fun': 1043, 'everywhere': 849, 'like': 1471, 'computer': 532, 'wait try': 2908, 'really': 2180, 'good': 1103, 'idea': 1319, 'outstanding': 1917, 'bought': 276, 'made': 1585, 'two': 2832, 'really good': 2183, 'good idea': 1113, 'glad': 1082, 'cocker': 484, 'standard': 2531, 'puppy': 2129, 'loves': 1570, 'stuff': 2588, 'trust': 2815, 'brand': 284, 'superior': 2612, 'nutrition': 1830, 'compare': 523, 'labels': 1423, 'previous': 2084, 'feed': 908, 'mostly': 1696, 'corn': 573, 'little': 1510, 'healthy': 1238, 'happy': 1217, 'high': 1259, 'energy': 808, 'coat': 480, 'also': 67, 'smaller': 2453, 'stools': 2566, 'using': 2869, 'food': 986, 'months': 1692, 'find': 931, 'excellent': 854, 'fact': 877, 'dogs': 734, 'de': 648, 'coats': 483, 'condition': 537, 'overall': 1919, 'perfect': 1982, 'tasting': 2678, 'dog': 730, 'deal': 650, 'owner': 1923, 'around': 117, 'best': 207, 'ever': 833, 'love food': 1557, 'good tasting': 1125, 'good deal': 1108, 'ever used': 838, 'cats': 387, 'crazy': 601, 'last': 1431, 'thing': 2722, 'want': 2914, 'cat': 384, 'hate': 1228, 'buying': 334, 'cat food': 385, 'shipped': 2402, 'day': 646, 'ordered': 1899, 'arrived': 119, 'within': 2990, 'days': 647, 'live': 1515, 'order': 1896, 'nicely': 1753, 'packaged': 1928, 'price': 2086, 'got': 1133, 'lbs': 1447, 'oz': 1924, 'biscotti': 234, 'kitchen': 1411, 'cut': 630, 'big': 228, 'pieces': 2005, 'add': 17, 'shipping': 2403, 'comes': 512, 'per': 1977, 'piece': 2004, 'local': 1523, 'charges': 405, 'guess': 1194, 'homemade': 1278, 'flavor': 959, 'hard': 1220, 'crunchy': 615, 'not': 1778, 'eat': 780, 'without': 2992, 'eaten': 786, 'coffee': 491, 'tea': 2681, 'cocoa': 486, 'mine': 1666, 'tastes': 2672, 'fall': 881, 'apart': 107, 'almond': 59, 'wish': 2987, 'came': 356, 'favorite': 903, 'within days': 2991, 'coffee tea': 499, 'tastes great': 2675, 'mix': 1677, 'probably': 2099, 'something': 2479, 'would': 3017, 'everyday': 846, 'new': 1743, 'enough': 816, 'different': 698, 'special': 2504, 'recipe': 2204, 'fruity': 1038, 'fill': 925, 'bill': 232, 'quickly': 2147, 'no': 1755, 'aftertaste': 40, 'often': 1846, 'diet': 696, 'drinks': 759, 'highly': 1265, 'recommend': 2206, 'highly recommend': 1266, 'description': 683, 'powder': 2066, 'nothing': 1822, 'coconut': 488, 'even': 828, 'dissolve': 726, 'commercial': 517, 'unless': 2848, 'dark': 639, 'chocolate': 442, 'coated': 481, 'shake': 2389, 'ended': 807, 'chewing': 417, 'tasteless': 2671, 'rather': 2162, 'drinking': 757, 'additionally': 27, 'way': 2934, 'cardboard': 371, 'top': 2778, 'package': 1927, 'box': 279, 'opened': 1888, 'rated': 2161, 'zero': 3068, 'stars': 2537, 'quality': 2140, 'inexpensive': 1341, 'gave': 1054, 'one': 1862, 'away': 140, 'free': 1009, 'back': 147, 'later': 1441, 'terrible': 2701, 'using product': 2870, 'dark chocolate': 640, 'one package': 1873, 'two days': 2834, 'online': 1883, 'grocery': 1181, 'store': 2571, 'usually': 2872, 'products': 2116, 'able': 1, 'turn': 2828, 'cream': 602, 'butter': 326, 'super': 2609, 'adding': 24, 'water': 2930, 'barely': 171, 'buy': 328, 'quite': 2148, 'tasty': 2680, 'flavorful': 969, 'read': 2169, 'another': 94, 'review': 2255, 'making': 1602, 'complaint': 528, 'texture': 2705, 'virtually': 2895, 'grocery store': 1182, 'quite tasty': 2151, 'keep': 1385, 'toddler': 2767, 'protein': 2122, 'levels': 1463, 'delicious': 670, 'imagine': 1322, 'cooking': 570, 'sausage': 2318, 'large': 1429, 'onion': 1882, 'tablespoon': 2645, 'dried': 751, 'basil': 179, 'salt': 2300, 'pepper': 1975, 'potatoes': 2058, 'thick': 2717, 'cover': 593, 'chicken': 419, 'stock': 2562, 'soft': 2471, 'throw': 2744, 'pre': 2070, 'baby': 145, 'half': 1204, 'pound': 2061, 'frozen': 1032, 'work': 3000, 'fine': 941, 'put': 2138, 'minute': 1670, 'earlier': 769, 'stir': 2561, 'cooked': 567, 'serve': 2376, 'enjoy': 811, 'salt pepper': 2301, 'get': 1058, 'busy': 325, 'home': 1277, 'quick': 2145, 'meal': 1630, 'options': 1894, 'bit': 240, 'sweet': 2624, 'works': 3005, 'well': 2951, 'lots': 1551, 'types': 2838, 'vegetables': 2884, 'slice': 2444, 'done': 739, 'pan': 1941, 'make': 1592, 'cheese': 412, 'family': 882, 'enjoys': 815, 'peas': 1971, 'mixed': 1680, 'option': 1893, 'cook': 566, 'usual': 2871, 'finish': 943, 'sweetness': 2635, 'salty': 2305, 'easy': 776, 'works well': 3007, 'easy make': 777, 'company': 521, 'american': 88, 'classic': 471, 'business': 324, 'years': 3055, 'hot': 1289, 'sauce': 2316, 'bar': 168, 'none': 1772, 'brands': 288, 'reasonable': 2195, 'heat': 1243, 'bite': 241, 'adds': 29, 'unique': 2846, 'foods': 997, 'mild': 1660, 'dinners': 707, 'harder': 1224, 'green': 1172, 'die': 695, 'everything': 848, 'unfortunately': 2844, 'see': 2352, 'amazon': 82, 'three': 2738, 'grew': 1175, 'five': 955, 'six': 2436, 'bottles': 273, 'variety': 2878, 'shelves': 2397, 'times': 2760, 'go': 1092, 'run': 2287, 'mill': 1664, 'best hot': 213, 'hot sauce': 1295, 'not want': 1818, 'go back': 1094, 'least': 1451, 'meals': 1631, 'every': 839, 'eggs': 798, 'pizza': 2007, 'wrong': 3048, 'flavor not': 965, 'not hot': 1800, 'every day': 840, 'go wrong': 1095, 'thank': 2708, 'goodness': 1130, 'cannot': 363, 'stores': 2573, 'anymore': 99, 'internet': 1358, 'shopping': 2407, 'makes': 1597, 'living': 1519, 'town': 2788, 'long': 1533, 'saved': 2321, 'occasional': 1838, 'trip': 2810, 'city': 464, 'first': 946, 'name': 1723, 'basis': 180, 'ups': 2854, 'shipments': 2401, 'hit': 1270, 'miss': 1673, 'fit': 953, 'head': 1231, 'thank goodness': 2710, 'find product': 938, 'local grocery': 1524, 'grocery stores': 1183, 'great not': 1161, 'product good': 2110, 'local grocery stores': 1526, 'anything': 101, 'closer': 477, 'recently': 2203, 'restaurant': 2248, 'picky': 1999, 'old': 1853, 'always': 79, 'table': 2644, 'california': 347, 'south': 2500, 'mail': 1588, 'single': 2425, 'pouches': 2060, 'directly': 711, 'nothing like': 1823, 'order get': 1898, 'get little': 1064, 'single serve': 2426, 'found': 1004, 'search': 2342, 'edible': 792, 'gold': 1100, 'leaf': 1448, 'decided': 657, 'purchase': 2130, 'reading': 2172, 'rave': 2165, 'reviews': 2259, 'items': 1367, 'however': 1301, 'clearly': 474, 'consumed': 547, 'misleading': 1672, 'found product': 1006, 'food items': 990, 'purchased': 2131, 'item': 1366, 'cake': 342, 'called': 349, 'dust': 768, 'never': 1740, 'thought': 2735, 'im': 1321, 'looked': 1540, 'star': 2534, 'container': 555, 'small': 2451, 'worth': 3013, 'thought would': 2736, 'looked like': 1541, 'long way': 1535, 'multiple': 1718, 'four': 1007, 'ago': 45, 'running': 2288, 'things': 2723, 'themed': 2715, 'including': 1334, 'entire': 817, 'roast': 2275, 'onto': 1884, 'beautiful': 190, 'years ago': 3056, 'create': 606, 'leaves': 1454, 'son': 2486, 'lightly': 1470, 'result': 2250, 'color': 504, 'containers': 556, 'goes': 1096, 'extremely': 872, 'economical': 791, 'goes long': 1097, 'goes long way': 1098, 'allows': 58, 'nuts': 1833, 'show': 2411, 'people': 1973, 'amazed': 80, 'cute': 631, 'affordable': 37, 'set': 2383, 'party': 1958, 'size': 2437, 'since': 2424, 'ball': 164, 'etc': 825, 'hubby': 1303, 'loved': 1566, 'extra': 870, 'balls': 165, 'huge': 1304, 'knowing': 1416, 'satisfied': 2313, 'birthday': 233, 'year': 3052, 'grandson': 1144, 'turned': 2829, 'year old': 3054, 'natural': 1725, 'ingredients': 1346, 'preservatives': 2077, 'say': 2327, 'fantastic': 889, 'expiration': 867, 'date': 642, 'week': 2944, 'faster': 896, 'absolutely': 5, 'freeze': 1016, 'loss': 1548, 'weather': 2941, 'ship': 2399, 'cool': 572, 'bags': 154, 'cold': 501, 'packs': 1935, 'dry': 764, 'ice': 1313, 'arrive': 118, 'natural ingredients': 1726, 'expiration date': 868, 'would eat': 3021, 'beans': 187, 'asian': 125, 'sweets': 2636, 'bean': 186, 'paste': 1962, 'changing': 403, 'twice': 2831, 'sugar': 2600, 'cakes': 344, 'not like': 1801, 'ice cream': 1314, 'problems': 2101, 'no problems': 1765, 'yummy': 3067, 'smell': 2455, 'taste': 2657, 'not good': 1796, 'taste little': 2663, 'little sweet': 1514, 'need': 1733, 'feel': 910, 'mouth': 1699, 'good stuff': 1123, 'stuff like': 2589, 'feel good': 912, 'staple': 2533, 'gets': 1066, 'truly': 2814, 'spicy': 2511, 'spring': 2522, 'rolls': 2280, 'crispy': 609, 'ones': 1881, 'old loves': 1854, 'sweet spicy': 2627, 'fried': 1025, 'rice': 2260, 'introduced': 1360, 'chili': 423, 'burn': 321, 'give': 1076, 'heart': 1241, 'continue': 561, 'fish': 952, 'one day': 1867, 'chili sauce': 424, 'much': 1705, 'turkey': 2827, 'sandwiches': 2311, 'sour': 2496, 'expensive': 863, 'either': 799, 'pretty much': 2082, 'tasted': 2667, 'served': 2377, 'combination': 508, 'locally': 1529, 'wonderful': 2993, 'pork': 2044, 'tried': 2801, 'beef': 194, 'sure': 2620, 'terrific': 2703, 'find locally': 936, 'reasonable price': 2196, 'not sure': 1814, 'would good': 3026, 'good not': 1116, 'recommend product': 2208, 'highly recommend product': 1267, 'sooo': 2489, 'followed': 984, 'outside': 1916, 'sliced': 2445, 'lime': 1500, 'juice': 1379, 'nice': 1751, 'salad': 2294, 'kick': 1402, 'cilantro': 462, 'also good': 68, 'dipping': 709, 'amazing': 81, 'discovered': 719, 'someone': 2478, 'left': 1455, 'bottle': 271, 'picture': 2001, 'took': 2776, 'thai': 2707, 'night': 1754, 'red': 2214, 'everyone': 847, 'think': 2725, 'love stuff': 1563, 'kids': 1405, 'many': 1610, 'kids love': 1406, 'many things': 1614, 'looking': 1542, 'based': 175, 'chance': 400, 'likes': 1498, 'says': 2329, 'stuck': 2587, 'sometimes': 2483, 'label': 1422, 'based reviews': 176, 'no one': 1763, 'dinner': 706, 'blend': 252, 'meat': 1636, 'almost': 61, 'past': 1960, 'salsa': 2299, 'must': 1720, 'addicting': 22, 'sauces': 2317, 'eater': 787, 'vegetarian': 2885, 'play': 2016, 'key': 1398, 'average': 137, 'strong': 2582, 'garlic': 1051, 'children': 422, 'plus': 2027, 'calories': 353, 'tablespoons': 2646, 'fiber': 922, 'time': 2752, 'personal': 1988, 'issue': 1362, 'thin': 2720, 'clear': 473, 'skin': 2441, 'horrible': 1287, 'teeth': 2693, 'still': 2559, 'anyway': 105, 'lol': 1531, 'anyone': 100, 'others': 1910, 'fully': 1042, 'ordering': 1901, 'near': 1729, 'know': 1414, 'pay': 1963, 'care': 372, 'product amazon': 2107, 'local store': 1527, 'must say': 1721, 'picky eater': 2000, 'like much': 1486, 'like little': 1483, 'son loves': 2487, 'food like': 991, 'hard time': 1222, 'not get': 1794, 'makes feel': 1599, 'one best': 1864, 'ever tasted': 836, 'would recommend': 3037, 'recommend anyone': 2207, 'amazon price': 86, 'would recommend anyone': 3038, 'steaks': 2551, 'moved': 1701, 'trying': 2820, 'world': 3008, 'market': 1621, 'addicted': 21, 'mentioned': 1646, 'ways': 2939, 'salads': 2295, 'along': 64, 'fat': 897, 'dressing': 749, 'sodium': 2470, 'mg': 1651, 'amount': 90, 'added': 19, 'could not': 583, 'not find': 1793, 'trying find': 2822, 'fat free': 898, 'worth every': 3014, 'could not find': 584, 'shrimp': 2415, 'needs': 1737, 'give try': 1078, 'place': 2008, 'mom': 1687, 'hooked': 1283, 'upon': 2853, 'dip': 708, 'claim': 465, 'dislike': 724, 'kind': 1407, 'exotic': 858, 'check': 409, 'doubt': 743, 'dishes': 723, 'superb': 2611, 'seasoning': 2347, 'plain': 2010, 'authentic': 133, 'larger': 1430, 'open': 1886, 'save': 2319, 'mean': 1632, 'gotten': 1135, 'hand': 1207, 'else': 801, 'peanuts': 1969, 'coating': 482, 'spoon': 2518, 'hands': 1210, 'clean': 472, 'sounds': 2493, 'gross': 1184, 'toss': 2782, 'heavy': 1248, 'chopped': 457, 'ginger': 1072, 'splash': 2514, 'said': 2293, 'base': 174, 'marinade': 1619, 'bulk': 319, 'buffalo': 318, 'seems': 2358, 'seasoned': 2346, 'wow': 3041, 'whole': 2968, 'kept': 1389, 'refrigerator': 2218, 'problem': 2100, 'thicker': 2719, 'ketchup': 1391, 'slowly': 2450, 'almonds': 60, 'serving': 2379, 'never tried': 1742, 'particular': 1954, 'hope': 1284, 'might': 1658, 'next': 1749, 'pack': 1926, 'broken': 307, 'sent': 2372, 'asked': 128, 'return': 2253, 'original': 1908, 'cost': 576, 'process': 2102, 'returned': 2254, 'beyond': 227, 'split': 2516, 'replacement': 2240, 'next time': 1750, 'slightly': 2448, 'egg': 797, 'chinese': 426, 'roll': 2279, 'really great': 2184, 'also great': 69, 'msg': 1704, 'love fact': 1555, 'right amount': 2268, 'meats': 1637, 'purpose': 2136, 'cheap': 406, 'friends': 1028, 'sorry': 2490, 'brought': 309, 'family friends': 884, 'tiny': 2762, 'oven': 1918, 'minutes': 1671, 'sticky': 2558, 'brown': 310, 'sized': 2438, 'sell': 2363, 'portion': 2046, 'sort': 2491, 'pull': 2127, 'treat': 2797, 'remember': 2232, 'plenty': 2024, 'restaurants': 2249, 'one favorite': 1868, 'veggies': 2886, 'better': 218, 'taste better': 2658, 'dish': 722, 'service': 2378, 'several': 2385, 'fast': 893, 'reliable': 2231, 'recipes': 2205, 'look': 1537, 'milk': 1662, 'pasta': 1961, 'whole family': 2971, 'family loves': 885, 'fast easy': 894, 'whole family loves': 2972, 'exact': 850, 'depending': 680, 'person': 1987, 'consistently': 544, 'receive': 2199, 'rating': 2163, 'tough': 2787, 'guy': 1200, 'reviewers': 2258, 'five stars': 956, 'friend': 1026, 'runs': 2290, 'actual': 15, 'mother': 1697, 'fridge': 1024, 'round': 2285, 'thus': 2748, 'far': 890, 'disappointed': 713, 'instant': 1349, 'snack': 2462, 'hour': 1297, 'prices': 2095, 'soups': 2495, 'keeps': 1388, 'lost': 1549, 'pantry': 1949, 'like product': 1490, 'several years': 2387, 'years old': 3057, 'tasted great': 2669, 'dumplings': 767, 'cause': 389, 'taste great': 2661, 'gourmet': 1136, 'prime': 2097, 'saves': 2322, 'gift': 1070, 'wish could': 2988, 'amazon prime': 87, 'especially': 822, 'household': 1300, 'favorites': 905, 'sesame': 2382, 'seem': 2356, 'yum': 3066, 'one favorites': 1869, 'mellow': 1641, 'immediately': 1323, 'could find': 581, 'handy': 1211, 'anywhere': 106, 'hey': 1258, 'supposed': 2619, 'rich': 2263, 'full': 1039, 'wife': 2979, 'stand': 2530, 'consider': 539, 'learn': 1449, 'full flavor': 1041, 'saw': 2326, 'colors': 506, 'went': 2956, 'got home': 1134, 'prefer': 2071, 'jerky': 1376, 'finding': 940, 'chunks': 461, 'school': 2332, 'time finding': 2753, 'good one': 1117, 'hard time finding': 1223, 'lived': 1516, 'europe': 826, 'term': 2699, 'whenever': 2962, 'feeling': 914, 'espresso': 824, 'pop': 2035, 'experience': 865, 'hazelnut': 1230, 'center': 393, 'class': 470, 'beats': 189, 'hershey': 1257, 'ever since': 835, 'wanted': 2917, 'shown': 2413, 'favors': 906, 'holiday': 1276, 'bag': 150, 'loose': 1546, 'come': 511, 'gone': 1102, 'discount': 717, 'helped': 1250, 'paid': 1937, 'missing': 1675, 'like would': 1494, 'italy': 1365, 'told': 2769, 'chocolates': 449, 'gifts': 1071, 'candy': 358, 'inside': 1348, 'bonus': 265, 'packaging': 1930, 'though': 2733, 'compared': 524, 'regular': 2223, 'fan': 886, 'stomach': 2564, 'drinker': 755, 'low': 1573, 'acidic': 11, 'level': 1462, 'handle': 1209, 'aroma': 116, 'lasted': 1434, 'prompt': 2118, 'fresh': 1021, 'intact': 1353, 'store bought': 2572, 'tea drinker': 2684, 'long time': 1534, 'expectations': 860, 'smooth': 2458, 'bitter': 244, 'awesome': 141, 'take': 2647, 'tips': 2763, 'love tea': 1565, 'not bitter': 1784, 'teas': 2691, 'drank': 747, 'packet': 1932, 'sale': 2296, 'quantity': 2143, 'specifically': 2506, 'afternoon': 39, 'drink': 752, 'whether': 2963, 'typical': 2839, 'coffee drinker': 492, 'tea not': 2688, 'high quality': 1263, 'tea like': 2687, 'like one': 1489, 'schedule': 2331, 'choices': 453, 'basket': 181, 'personally': 1989, 'picked': 1998, 'us': 2856, 'totally': 2785, 'realized': 2179, 'simply': 2423, 'case': 382, 'grab': 1137, 'realize': 2178, 'incredible': 1336, 'find anywhere': 933, 'love hot': 1558, 'really love': 2188, 'pure': 2134, 'helps': 1253, 'little bit': 1511, 'great flavor': 1157, 'white': 2967, 'orange': 1895, 'overly': 1920, 'real': 2175, 'good taste': 1124, 'cracked': 595, 'kinda': 1408, 'bad': 149, 'strong not': 2585, 'not bad': 1780, 'ate': 130, 'kidding': 1404, 'exactly': 851, 'ideal': 1320, 'threw': 2741, 'gallon': 1048, 'freezer': 1017, 'arrived time': 120, 'pot': 2052, 'mixture': 1683, 'ten': 2696, 'much better': 1706, 'sound': 2492, 'whatever': 2959, 'avoid': 138, 'house': 1299, 'eating': 789, 'life': 1466, 'fed': 907, 'kinds': 1409, 'supermarket': 2613, 'lives': 1518, 'kit': 1410, 'terms': 2700, 'morning': 1694, 'stop': 2567, 'hungry': 1307, 'working': 3003, 'choice': 452, 'feeding': 909, 'science': 2333, 'bowl': 278, 'sitting': 2434, 'started': 2539, 'start': 2538, 'middle': 1657, 'servings': 2381, 'less': 1459, 'cup': 617, 'became': 191, 'figured': 924, 'wake': 2910, 'serious': 2374, 'desk': 686, 'paper': 1950, 'door': 741, 'general': 1055, 'soon': 2488, 'hours': 1298, 'maybe': 1629, 'funny': 1044, 'end': 806, 'sad': 2291, 'weeks': 2946, 'non': 1771, 'money': 1688, 'vet': 2890, 'second': 2349, 'adult': 33, 'saying': 2328, 'basically': 178, 'garbage': 1050, 'ground': 1185, 'bunch': 320, 'vitamins': 2900, 'beginning': 198, 'began': 196, 'wellness': 2955, 'formula': 1001, 'blue': 256, 'eats': 790, 'looks': 1544, 'initial': 1347, 'dad': 633, 'spilled': 2513, 'floor': 979, 'favor': 902, 'figure': 923, 'please': 2020, 'first tried': 951, 'science diet': 2334, 'one sitting': 1876, 'went back': 2957, 'would get': 3023, 'not really': 1811, 'every morning': 842, 'something else': 2481, 'not care': 1786, 'two weeks': 2835, 'weeks ago': 2947, 'food one': 994, 'three times': 2740, 'pet': 1990, 'certainly': 398, 'worst': 3012, 'snap': 2465, 'lock': 1530, 'difficult': 701, 'close': 475, 'properly': 2120, 'side': 2417, 'allow': 56, 'air': 50, 'important': 1324, 'stale': 2529, 'fats': 900, 'rancid': 2155, 'human': 1306, 'let': 1461, 'animal': 92, 'literally': 1509, 'range': 2156, 'oldest': 1856, 'diagnosed': 691, 'couple': 588, 'disease': 720, 'yet': 3062, 'needed': 1734, 'paying': 1965, 'attention': 131, 'switch': 2639, 'active': 14, 'support': 2618, 'older': 1855, 'weight': 2948, 'rest': 2247, 'pounds': 2063, 'noticed': 1825, 'regularly': 2229, 'although': 78, 'diarrhea': 693, 'lab': 1421, 'results': 2251, 'nutritional': 1831, 'claims': 466, 'sites': 2433, 'various': 2881, 'health': 1232, 'listed': 1508, 'point': 2031, 'appears': 110, 'slight': 2447, 'difference': 697, 'vitamin': 2899, 'gain': 1047, 'noted': 1821, 'switching': 2641, 'luck': 1581, 'months ago': 1693, 'things like': 2724, 'even though': 830, 'sensitive': 2371, 'mention': 1645, 'healthier': 1236, 'stronger': 2586, 'wet': 2958, 'palatable': 1939, 'senior': 2369, 'not mention': 1802, 'junk': 1381, 'higher': 1264, 'organic': 1904, 'pets': 1993, 'count': 585, 'closest': 478, 'issues': 1363, 'junk food': 1382, 'not healthy': 1799, 'definitely': 663, 'cans': 365, 'contents': 560, 'value': 2875, 'wont': 2998, 'seems like': 2359, 'definitely not': 666, 'mistake': 1676, 'research': 2245, 'iams': 1312, 'main': 1589, 'interesting': 1357, 'digest': 703, 'constantly': 545, 'means': 1633, 'consumption': 550, 'dead': 649, 'animals': 93, 'cheaper': 407, 'trash': 2794, 'appealing': 109, 'recommendation': 2210, 'common': 518, 'sense': 2370, 'newmans': 1748, 'wholesome': 2977, 'record': 2212, 'required': 2242, 'would not': 3034, 'not recommend': 1812, 'much less': 1710, 'not worth': 1819, 'pet food': 1991, 'would not recommend': 3035, 'move': 1700, 'maker': 1596, 'tummy': 2825, 'brewing': 301, 'licorice': 1464, 'shared': 2394, 'warm': 2922, 'forget': 999, 'produced': 2105, 'german': 1057, 'firm': 945, 'believe': 201, 'penny': 1972, 'great little': 1160, 'drinking tea': 758, 'every penny': 843, 'digestive': 704, 'mint': 1669, 'tired': 2764, 'mornings': 1695, 'substitute': 2596, 'decaf': 652, 'lemon': 1456, 'acid': 10, 'sells': 2366, 'elsewhere': 802, 'herbal': 1255, 'vegetable': 2883, 'soup': 2494, 'getting': 1067, 'reminds': 2235, 'hot water': 1296, 'not fan': 1792, 'evening': 831, 'recommended': 2211, 'good quality': 1120, 'quality product': 2142, 'brews': 302, 'opening': 1889, 'alone': 63, 'naturally': 1727, 'reach': 2167, 'satisfy': 2314, 'cravings': 600, 'really taste': 2191, 'taste like': 2662, 'like good': 1481, 'girlfriend': 1075, 'completely': 531, 'subscribe': 2593, 'customers': 629, 'gf': 1069, 'wants': 2920, 'tea bags': 2683, 'wish would': 2989, 'subscribe save': 2594, 'smells': 2457, 'addition': 25, 'blends': 253, 'timely': 2758, 'manner': 1606, 'thanks': 2712, 'tastes good': 2674, 'makes great': 1601, 'timely manner': 2759, 'seal': 2340, 'brew': 298, 'easier': 774, 'gravy': 1148, 'already': 66, 'takes': 2649, 'number': 1826, 'country': 587, 'chose': 458, 'bisquick': 237, 'lobster': 1522, 'heard': 1240, 'super easy': 2610, 'except': 856, 'training': 2790, 'flavors': 972, 'liver': 1517, 'power': 2068, 'carry': 380, 'example': 853, 'walk': 2911, 'worry': 3010, 'variety flavors': 2879, 'treats': 2798, 'ok': 1851, 'medium': 1638, 'calorie': 351, 'sit': 2431, 'stay': 2548, 'drop': 762, 'leave': 1453, 'messy': 1648, 'pocket': 2028, 'purse': 2137, 'travel': 2795, 'downside': 745, 'trick': 2800, 'scent': 2330, 'low calorie': 1574, 'ton': 2773, 'ingredient': 1344, 'list': 1506, 'opposed': 1892, 'calories per': 355, 'also love': 71, 'ingredient list': 1345, 'flavored': 968, 'knows': 1418, 'coming': 513, 'aid': 49, 'eye': 873, 'putting': 2139, 'provide': 2123, 'supply': 2617, 'mind': 1665, 'wheat': 2960, 'flour': 980, 'happens': 1214, 'allergic': 53, 'nor': 1774, 'short': 2408, 'artificial': 121, 'quite bit': 2149, 'first ingredient': 948, 'wheat flour': 2961, 'nearly': 1731, 'heaven': 1245, 'packets': 1933, 'may': 1627, 'product arrived': 2109, 'good condition': 1106, 'no taste': 1767, 'taste really': 2665, 'soy': 2501, 'nutrients': 1829, 'nutritious': 1832, 'calcium': 346, 'cholesterol': 455, 'product great': 2111, 'great price': 1162, 'buy case': 331, 'send': 2367, 'husband': 1308, 'peach': 1966, 'source': 2499, 'refreshing': 2217, 'summer': 2606, 'overwhelming': 1922, 'black': 248, 'flavoring': 970, 'sweetened': 2630, 'somewhat': 2484, 'sweetener': 2631, 'contains': 558, 'kosher': 1420, 'concerns': 535, 'contact': 551, 'black tea': 250, 'tea leaves': 2686, 'green tea': 1174, 'want something': 2915, 'cookies': 569, 'death': 651, 'filled': 926, 'crumbs': 613, 'needless': 1735, 'needless say': 1736, 'regret': 2222, 'mrs': 1703, 'farms': 892, 'recent': 2202, 'chip': 427, 'baked': 157, 'cookie': 568, 'awful': 142, 'bananas': 167, 'part': 1951, 'chips': 429, 'ratio': 2164, 'sugary': 2603, 'sales': 2297, 'replace': 2238, 'disgusting': 721, 'happened': 1213, 'saving': 2323, 'opportunity': 1891, 'likely': 1497, 'chocolate chip': 443, 'chip cookies': 428, 'milk chocolate': 1663, 'tastes like': 2676, 'chocolate chips': 445, 'absolutely no': 8, 'no idea': 1760, 'hard find': 1221, 'chocolate chip cookies': 444, 'fructose': 1033, 'syrup': 2642, 'yes': 3060, 'iron': 1361, 'carbs': 370, 'include': 1331, 'banana': 166, 'poor': 2034, 'cents': 394, 'ounce': 1913, 'maintain': 1590, 'freshness': 1023, 'bigger': 231, 'drawback': 748, 'thinks': 2729, 'ounces': 1914, 'sealed': 2341, 'high fructose': 1260, 'fructose corn': 1034, 'corn syrup': 574, 'health food': 1234, 'high fructose corn': 1261, 'fructose corn syrup': 1035, 'candies': 357, 'seeds': 2354, 'wonders': 2997, 'individually': 1339, 'wrapped': 3043, 'slow': 2449, 'peanut': 1967, 'individually wrapped': 1340, 'first time': 950, 'eat one': 784, 'ran': 2154, 'afford': 36, 'jack': 1368, 'seriously': 2375, 'folks': 982, 'system': 2643, 'sticks': 2557, 'oatmeal': 1834, 'body': 263, 'glass': 1085, 'improved': 1328, 'growing': 1192, 'shower': 2412, 'boring': 269, 'readily': 2171, 'crap': 598, 'one star': 1877, 'right away': 2269, 'straight': 2577, 'website': 2943, 'really enjoy': 2181, 'longer': 1536, 'allowed': 57, 'soda': 2469, 'feel better': 911, 'no longer': 1761, 'get free': 1062, 'free shipping': 1015, 'could get': 582, 'well worth': 2954, 'worth price': 3016, 'machine': 1584, 'collection': 503, 'oh': 1847, 'deep': 661, 'tell': 2694, 'highly recommended': 1268, 'till': 2751, 'best way': 217, 'cant': 366, 'love product': 1562, 'pleasure': 2023, 'french': 1018, 'web': 2942, 'markets': 1622, 'area': 114, 'bargain': 172, 'bland': 251, 'seasonings': 2348, 'costs': 578, 'great tasting': 1167, 'best ever': 212, 'shipping costs': 2404, 'vacation': 2873, 'normally': 1776, 'bother': 270, 'line': 1504, 'dark roast': 641, 'no bitter': 1757, 'bitter taste': 246, 'best tasting': 215, 'tasting coffee': 2679, 'coffee ever': 493, 'best coffee': 210, 'bodied': 262, 'chocolaty': 451, 'full bodied': 1040, 'rich flavor': 2264, 'find local': 935, 'ever tried': 837, 'tried many': 2805, 'drip': 760, 'finished': 944, 'good coffee': 1105, 'coffee maker': 497, 'use two': 2863, 'sip': 2429, 'breakfast': 294, 'starbucks': 2535, 'wine': 2983, 'generally': 1056, 'fell': 917, 'beverage': 224, 'press': 2078, 'buds': 317, 'guys': 1201, 'sample': 2306, 'anything else': 102, 'real deal': 2176, 'fell love': 918, 'throw away': 2745, 'taste buds': 2659, 'cafe': 338, 'delighted': 674, 'com': 507, 'order amazon': 1897, 'amazon com': 83, 'great way': 1170, 'bold': 264, 'lover': 1568, 'coffees': 500, 'love coffee': 1554, 'coffee like': 496, 'many different': 1611, 'different brands': 699, 'one bag': 1863, 'tried many different': 2806, 'christmas': 460, 'advertised': 35, 'office': 1845, 'reorder': 2237, 'covered': 594, 'delightful': 675, 'smelled': 2456, 'lowest': 1580, 'seen': 2360, 'tasted good': 2668, 'big hit': 230, 'stevia': 2555, 'iced': 1315, 'cereal': 396, 'way go': 2937, 'iced tea': 1316, 'great stuff': 1165, 'food store': 995, 'thanks amazon': 2713, 'tried several': 2809, 'taste not': 2664, 'health food store': 1235, 'alternative': 75, 'splenda': 2515, 'equal': 819, 'lasts': 1436, 'healthier alternative': 1237, 'lasts long': 1437, 'lasts long time': 1438, 'powdered': 2067, 'bitterness': 247, 'yogurt': 3063, 'guilt': 1196, 'dessert': 688, 'liquid': 1505, 'version': 2889, 'beverages': 225, 'eventually': 832, 'no bitterness': 1758, 'exactly like': 852, 'like real': 1491, 'guilt free': 1197, 'side dish': 2418, 'sweeteners': 2632, 'effects': 795, 'baking': 160, 'similar': 2421, 'effect': 793, 'daily': 634, 'find good': 934, 'get good': 1063, 'skeptical': 2440, 'felt': 919, 'pleased': 2021, 'another brand': 95, 'artificial sweeteners': 124, 'apple': 111, 'notice': 1824, 'like coffee': 1476, 'per cup': 1980, 'extract': 871, 'form': 1000, 'convenient': 565, 'teaspoon': 2692, 'perfectly': 1984, 'far best': 891, 'liked': 1495, 'fruit': 1036, 'switched': 2640, 'blood': 254, 'yeah': 3051, 'couple years': 590, 'really liked': 2186, 'less expensive': 1460, 'price good': 2088, 'sweet not': 2625, 'blood sugar': 255, 'auto': 134, 'month': 1689, 'great coffee': 1154, 'tea one': 2689, 'mixes': 1681, 'thoroughly': 2732, 'buyer': 333, 'success': 2598, 'stove': 2576, 'hot cocoa': 1293, 'odd': 1840, 'sold': 2474, 'concerned': 534, 'content': 559, 'traditional': 2789, 'tried brands': 2802, 'tastes better': 2673, 'different flavors': 700, 'flavors great': 974, 'charge': 404, 'premium': 2073, 'tried every': 2804, 'food stores': 996, 'find amazon': 932, 'really like': 2185, 'like not': 1488, 'carb': 369, 'tolerate': 2770, 'sugars': 2602, 'agave': 42, 'honey': 1281, 'dates': 643, 'raise': 2152, 'therefore': 2716, 'plant': 2012, 'parts': 1957, 'thinking': 2728, 'usa': 2857, 'companies': 520, 'honest': 1279, 'individual': 1338, 'alcohol': 52, 'vanilla': 2876, 'unlike': 2849, 'heated': 1244, 'raw': 2166, 'low carb': 1576, 'like no': 1487, 'way much': 2938, 'sweet taste': 2628, 'bitter aftertaste': 245, 'trying eat': 2821, 'eat healthy': 782, 'nasty': 1724, 'ahead': 47, 'game': 1049, 'every single': 844, 'use one': 2861, 'one packet': 1874, 'chemicals': 414, 'diabetic': 690, 'chemical': 413, 'uses': 2868, 'winter': 2985, 'taste good': 2660, 'found amazon': 1005, 'maltodextrin': 1603, 'hated': 1229, 'lemonade': 1457, 'bring': 304, 'thrown': 2747, 'several months': 2386, 'decided give': 658, 'absolutely delicious': 6, 'one not': 1871, 'product not': 2113, 'sweeter': 2633, 'sweetner': 2634, 'dissolves': 727, 'muffins': 1716, 'jar': 1373, 'tsp': 2823, 'given': 1079, 'impressed': 1327, 'brands tried': 290, 'brands not': 289, 'anytime': 104, 'unhealthy': 2845, 'tooth': 2777, 'safe': 2292, 'comparison': 525, 'time tried': 2756, 'tried product': 2808, 'sweet tooth': 2629, 'cutting': 632, 'flat': 958, 'amounts': 91, 'vendor': 2887, 'weird': 2950, 'dollars': 738, 'additives': 28, 'simple': 2422, 'used buy': 2865, 'buy product': 332, 'find stores': 939, 'use product': 2862, 'like better': 1472, 'especially like': 823, 'texture taste': 2706, 'vs': 2902, 'lid': 1465, 'product works': 2114, 'customer': 627, 'customer service': 628, 'nectar': 1732, 'actually': 16, 'due': 766, 'smoothies': 2461, 'breads': 292, 'cacao': 337, 'help': 1249, 'unable': 2841, 'previously': 2085, 'last year': 1433, 'drink lot': 754, 'gas': 1052, 'breath': 296, 'terrier': 2702, 'allergies': 54, 'girl': 1074, 'upset': 2855, 'forward': 1002, 'food allergies': 987, 'stopped': 2569, 'carrying': 381, 'searching': 2344, 'biscuits': 236, 'biscuit': 235, 'one two': 1880, 'tried one': 2807, 'increase': 1335, 'complaints': 529, 'china': 425, 'oats': 1835, 'worked': 3001, 'admit': 30, 'boyfriend': 282, 'otherwise': 1912, 'reviewer': 2256, 'plastic': 2014, 'continue buy': 562, 'good price': 1118, 'delivery': 677, 'negative': 1738, 'packed': 1931, 'improvement': 1329, 'zip': 3069, 'consumer': 548, 'goods': 1131, 'storage': 2570, 'would like': 3030, 'plastic bag': 2015, 'open bag': 1887, 'save money': 2320, 'people like': 1974, 'seemed': 2357, 'much cheaper': 1707, 'crumbly': 612, 'bubble': 315, 'gum': 1199, 'rock': 2278, 'story': 2575, 'chew': 416, 'third': 2731, 'child': 420, 'boy': 281, 'enjoyed': 813, 'normal': 1775, 'break': 293, 'no way': 1769, 'double': 742, 'bbq': 185, 'considering': 541, 'gluten': 1086, 'price right': 2092, 'price would': 2093, 'herbs': 1256, 'adults': 34, 'brewed': 299, 'watch': 2927, 'word': 2999, 'decide': 656, 'not great': 1797, 'great taste': 1166, 'find one': 937, 'crackers': 597, 'snacks': 2464, 'salted': 2304, 'job': 1377, 'not overly': 1807, 'like many': 1485, 'cracker': 596, 'note': 1820, 'page': 1936, 'meant': 1634, 'bottom': 274, 'able find': 2, 'bottom line': 275, 'light': 1467, 'spread': 2521, 'placed': 2009, 'seeing': 2355, 'lately': 1440, 'reason': 2194, 'information': 1343, 'aside': 126, 'not picky': 1809, 'good value': 1127, 'expecting': 862, 'waste': 2924, 'fragile': 1008, 'waste money': 2925, 'sister': 2430, 'excited': 857, 'test': 2704, 'understand': 2843, 'future': 1046, 'make sure': 1595, 'guests': 1195, 'throwing': 2746, 'mini': 1668, 'bites': 242, 'matter': 1626, 'state': 2544, 'beware': 226, 'corner': 575, 'wrappers': 3044, 'packing': 1934, 'fast shipping': 895, 'second time': 2350, 'well packed': 2953, 'really enjoyed': 2182, 'seller': 2364, 'would buy': 3018, 'pass': 1959, 'together': 2768, 'bed': 193, 'commented': 515, 'not buy': 1785, 'sinus': 2428, 'spent': 2508, 'tasted like': 2670, 'major': 1591, 'included': 1332, 'cups': 624, 'pain': 1938, 'would make': 3032, 'produce': 2104, 'steal': 2552, 'post': 2051, 'throughout': 2743, 'many years': 1616, 'couple days': 589, 'taking': 2650, 'skip': 2442, 'burnt': 323, 'pressure': 2079, 'english': 810, 'one cup': 1866, 'starting': 2541, 'allergy': 55, 'season': 2345, 'particularly': 1955, 'tons': 2775, 'rid': 2265, 'not tried': 1817, 'works great': 3006, 'change': 401, 'steep': 2553, 'neither': 1739, 'decided try': 660, 'tea bag': 2682, 'strong enough': 2583, 'sleep': 2443, 'reading reviews': 2173, 'wonderful flavor': 2994, 'numerous': 1827, 'lack': 1424, 'question': 2144, 'pouch': 2059, 'empty': 805, 'brother': 308, 'product anyone': 2108, 'recommend product anyone': 2209, 'helpful': 1251, 'gives': 1080, 'able get': 3, 'year ago': 3053, 'talk': 2651, 'nose': 1777, 'would highly': 3028, 'would highly recommend': 3029, 'popular': 2043, 'giving': 1081, 'miles': 1661, 'apparently': 108, 'wide': 2978, 'expect': 859, 'met': 1649, 'lacks': 1426, 'not available': 1779, 'mix made': 1678, 'receiving': 2201, 'packages': 1929, 'contain': 553, 'honestly': 1280, 'agree': 46, 'unit': 2847, 'bucks': 316, 'look forward': 1538, 'movie': 1702, 'site': 2432, 'great snack': 1164, 'ask': 127, 'taste texture': 2666, 'better price': 219, 'fake': 880, 'true': 2813, 'consume': 546, 'shot': 2409, 'road': 2274, 'trips': 2811, 'parties': 1956, 'would never': 3033, 'provided': 2124, 'costco': 577, 'discover': 718, 'offers': 1844, 'buy amazon': 329, 'absolutely love': 7, 'balance': 162, 'stocking': 2563, 'instructions': 1352, 'carries': 377, 'prepare': 2074, 'italian': 1364, 'ready': 2174, 'preference': 2072, 'easy prepare': 778, 'local grocery store': 1525, 'lose': 1547, 'creamy': 605, 'intake': 1354, 'san': 2308, 'lovely': 1567, 'rose': 2283, 'caffeine': 340, 'sending': 2368, 'punch': 2128, 'boys': 283, 'happily': 1216, 'felidae': 916, 'shape': 2391, 'touch': 2786, 'two years': 2836, 'new food': 1744, 'lays': 1444, 'purina': 2135, 'changed': 402, 'fairly': 879, 'early': 770, 'effective': 794, 'fur': 1045, 'happier': 1215, 'looks like': 1545, 'kibble': 1401, 'mess': 1647, 'good thing': 1126, 'noise': 1770, 'sick': 2416, 'purchasing': 2133, 'eaters': 788, 'write': 3045, 'stop eating': 2568, 'food not': 993, 'entirely': 818, 'certain': 397, 'age': 43, 'lower': 1579, 'consistent': 543, 'remove': 2236, 'cats love': 388, 'dairy': 635, 'oil': 1848, 'perhaps': 1985, 'bake': 156, 'dairy free': 636, 'awhile': 143, 'makes best': 1598, 'shame': 2390, 'babies': 144, 'use much': 2860, 'even better': 829, 'loaded': 1520, 'processed': 2103, 'known': 1417, 'frequently': 1020, 'law': 1442, 'prepared': 2075, 'rate': 2160, 'may not': 1628, 'willing': 2981, 'match': 1625, 'like regular': 1492, 'amazon not': 85, 'situation': 2435, 'local stores': 1528, 'stores not': 2574, 'doctor': 729, 'retail': 2252, 'pros': 2121, 'reduced': 2216, 'present': 2076, 'horses': 1288, 'setting': 2384, 'portable': 2045, 'liking': 1499, 'shocked': 2405, 'hold': 1273, 'surprisingly': 2623, 'containing': 557, 'step': 2554, 'design': 684, 'versatile': 2888, 'product much': 2112, 'would great': 3027, 'get lot': 1065, 'metal': 1650, 'relatively': 2230, 'moist': 1685, 'surprise': 2621, 'square': 2524, 'tight': 2750, 'fits': 954, 'effort': 796, 'room': 2281, 'not much': 1803, 'no problem': 1764, 'not big': 1783, 'much easier': 1708, 'require': 2241, 'strength': 2581, 'solid': 2475, 'pick': 1997, 'style': 2592, 'separate': 2373, 'wanting': 2919, 'easy use': 779, 'pretty good': 2081, 'not even': 1791, 'quick easy': 2146, 'bag one': 153, 'not quite': 1810, 'bag not': 152, 'one time': 1879, 'winner': 2984, 'pictures': 2002, 'photo': 1996, 'time not': 2755, 'happen': 1212, 'device': 689, 'promptly': 2119, 'trouble': 2812, 'carried': 376, 'stated': 2545, 'contained': 554, 'solution': 2476, 'afraid': 38, 'melted': 1643, 'pet store': 1992, 'dogs love': 736, 'em': 803, 'bought product': 277, 'excellent product': 855, 'glad found': 1084, 'dogs like': 735, 'dont': 740, 'dog loves': 733, 'drops': 763, 'limit': 1502, 'buying product': 335, 'minerals': 1667, 'possible': 2050, 'thrilled': 2742, 'price great': 2089, 'supplier': 2616, 'chocolate flavor': 447, 'not believe': 1781, 'subtle': 2597, 'mango': 1605, 'selection': 2362, 'fabulous': 875, 'good would': 1129, 'finally': 929, 'intense': 1355, 'finally found': 930, 'good job': 1114, 'lovers': 1569, 'fans': 888, 'sturdy': 2591, 'share': 2393, 'front': 1030, 'somehow': 2477, 'handful': 1208, 'whole bag': 2969, 'crisps': 608, 'filling': 928, 'satisfying': 2315, 'crunch': 614, 'habit': 1202, 'snacking': 2463, 'grow': 1191, 'potato': 2054, 'fattening': 901, 'flavorings': 971, 'type': 2837, 'little less': 1512, 'potato chip': 2056, 'quite good': 2150, 'low calories': 1575, 'calories fat': 354, 'cases': 383, 'contacted': 552, 'manufacturer': 1608, 'response': 2246, 'chips no': 438, 'no flavor': 1759, 'disappointing': 714, 'choke': 454, 'begin': 197, 'good reviews': 1121, 'described': 682, 'wasted': 2926, 'not eat': 1789, 'grams': 1143, 'offered': 1842, 'potato chips': 2057, 'sea': 2337, 'softer': 2472, 'popcorn': 2038, 'watching': 2929, 'love flavor': 1556, 'however not': 1302, 'like flavors': 1480, 'rice cakes': 2261, 'grains': 1141, 'per serving': 1981, 'would definitely': 3019, 'definitely recommend': 668, 'would definitely recommend': 3020, 'best one': 214, 'regular basis': 2224, 'sea salt': 2338, 'regular chips': 2226, 'co': 479, 'worker': 3002, 'counter': 586, 'drive': 761, 'craving': 599, 'roasted': 2276, 'soybean': 2503, 'jars': 1374, 'missed': 1674, 'oily': 1850, 'eat anything': 781, 'flavor like': 963, 'per bag': 1978, 'overpowering': 1921, 'tortilla': 2780, 'big fan': 229, 'tortilla chips': 2781, 'greasy': 1150, 'fingers': 942, 'also like': 70, 'spices': 2510, 'not strong': 1813, 'stash': 2543, 'father': 899, 'visit': 2896, 'bits': 243, 'boxes': 280, 'priced': 2094, 'cents per': 395, 'per box': 1979, 'one box': 1865, 'pudding': 2126, 'subscription': 2595, 'graham': 1138, 'whipped': 2965, 'topping': 2779, 'frosting': 1031, 'nut': 1828, 'pie': 2003, 'limited': 1503, 'cake mix': 343, 'fancy': 887, 'husband loves': 1310, 'available amazon': 136, 'rarely': 2158, 'cinnamon': 463, 'eat much': 783, 'no sugar': 1766, 'damage': 637, 'fair': 878, 'whole foods': 2973, 'bars': 173, 'fresher': 1022, 'shelf': 2395, 'enjoyable': 812, 'first one': 949, 'chewy': 418, 'heavier': 1246, 'kid': 1403, 'last long': 1432, 'difficult find': 702, 'childhood': 421, 'plan': 2011, 'ever eaten': 834, 'control': 563, 'portion control': 2047, 'way better': 2935, 'thank amazon': 2709, 'great buy': 1153, 'station': 2547, 'every time': 845, 'time used': 2757, 'pleasant': 2017, 'looking forward': 1543, 'grass': 1147, 'lunch': 1582, 'favorite flavor': 904, 'gluten free': 1087, 'noodles': 1773, 'shaped': 2392, 'lunches': 1583, 'combined': 509, 'spice': 2509, 'benefit': 203, 'ability': 0, 'liked much': 1496, 'stick': 2556, 'suggested': 2605, 'carefully': 374, 'food no': 992, 'not one': 1804, 'stay away': 2549, 'batch': 182, 'mixing': 1682, 'offer': 1841, 'provides': 2125, 'spicy thai': 2512, 'talking': 2652, 'microwave': 1654, 'good flavor': 1111, 'joe': 1378, 'tastier': 2677, 'pleasing': 2022, 'hint': 1269, 'scratch': 2336, 'best thing': 216, 'like buy': 1473, 'melt': 1642, 'add little': 18, 'good hot': 1112, 'many flavors': 1612, 'make great': 1593, 'bread': 291, 'sunflower': 2607, 'flax': 977, 'grinding': 1179, 'good product': 1119, 'seed': 2353, 'grind': 1177, 'flax seed': 978, 'grinder': 1178, 'sprinkle': 2523, 'pancakes': 1946, 'ground coffee': 1186, 'husband love': 1309, 'reasonably': 2197, 'reasonably priced': 2198, 'not disappointed': 1787, 'benefits': 204, 'fruits': 1037, 'started drinking': 2540, 'health benefits': 1233, 'omega': 1861, 'golden': 1101, 'cup coffee': 619, 'bob': 259, 'delivered': 676, 'suggest': 2604, 'bob red': 260, 'red mill': 2215, 'bob red mill': 261, 'makes good': 1600, 'buy bulk': 330, 'way get': 2936, 'oils': 1849, 'loaf': 1521, 'dough': 744, 'tin': 2761, 'knew': 1412, 'checked': 410, 'lighter': 1469, 'baked goods': 158, 'also use': 74, 'google': 1132, 'good way': 1128, 'absolute': 4, 'regarding': 2221, 'dog food': 731, 'wonderfully': 2995, 'calorie count': 352, 'partially': 1952, 'hydrogenated': 1311, 'partially hydrogenated': 1953, 'grown': 1193, 'states': 2546, 'keep mind': 1386, 'not sweet': 1815, 'written': 3047, 'following': 985, 'hair': 1203, 'manufacturers': 1609, 'chips taste': 441, 'baby food': 146, 'soy sauce': 2502, 'crumble': 611, 'great healthy': 1159, 'no matter': 1762, 'celiac': 391, 'dr': 746, 'celiac disease': 392, 'wrote': 3049, 'email': 804, 'manufactured': 1607, 'certified': 399, 'current': 625, 'members': 1644, 'additional': 26, 'comments': 516, 'despite': 687, 'granted': 1145, 'read reviews': 2170, 'varieties': 2877, 'forward trying': 1003, 'thankful': 2711, 'disappointment': 715, 'incredibly': 1337, 'learned': 1450, 'decent': 655, 'aware': 139, 'portions': 2048, 'complete': 530, 'fix': 957, 'like lot': 1484, 'surprised': 2622, 'would love': 3031, 'daughter loves': 645, 'grainy': 1142, 'didnt': 694, 'delicious not': 672, 'herb': 1254, 'root': 2282, 'starts': 2542, 'taken': 2648, 'expected': 861, 'great texture': 1168, 'adore': 32, 'whole lot': 2975, 'really tasty': 2192, 'grease': 1149, 'originally': 1909, 'supermarkets': 2614, 'occasionally': 1839, 'peanut butter': 1968, 'crisp': 607, 'low fat': 1577, 'price amazon': 2087, 'amazon great': 84, 'savory': 2325, 'stays': 2550, 'price per': 2090, 'glad find': 1083, 'volume': 2901, 'dissapointed': 725, 'become': 192, 'purchases': 2132, 'like eating': 1477, 'blueberries': 257, 'delight': 673, 'whipped cream': 2966, 'delicious easy': 671, 'boot': 268, 'earth': 771, 'interested': 1356, 'earth best': 772, 'love love': 1559, 'strange': 2578, 'refused': 2220, 'describe': 681, 'hoping': 1286, 'almost like': 62, 'anything like': 103, 'feel like': 913, 'month old': 1690, 'offering': 1843, 'good snack': 1122, 'whole wheat': 2976, 'alot': 65, 'grain': 1139, 'whole grain': 2974, 'selling': 2365, 'stage': 2528, 'get enough': 1061, 'runny': 2289, 'consistency': 542, 'think could': 2726, 'instantly': 1350, 'brown rice': 311, 'rice flour': 2262, 'really not': 2189, 'much one': 1712, 'sweet potato': 2626, 'reminded': 2234, 'forever': 998, 'careful': 373, 'loves food': 1571, 'young': 3065, 'watery': 2933, 'update': 2852, 'today': 2766, 'combo': 510, 'brings': 305, 'time make': 2754, 'really likes': 2187, 'thicken': 2718, 'carrot': 378, 'not best': 1782, 'face': 876, 'complained': 527, 'wrap': 3042, 'somewhere': 2485, 'would try': 3040, 'little one': 1513, 'one one': 1872, 'tend': 2697, 'target': 2654, 'mustard': 1722, 'greatest': 1171, 'helping': 1252, 'get amazon': 1059, 'waiting': 2909, 'would expect': 3022, 'mushy': 1719, 'canned': 361, 'lacking': 1425, 'not taste': 1816, 'felt like': 920, 'pineapple': 2006, 'never buy': 1741, 'book': 266, 'caramel': 368, 'still great': 2560, 'like fact': 1478, 'artificial flavors': 122, 'tongue': 2774, 'blueberry': 258, 'ahoy': 48, 'chips ahoy': 430, 'would rather': 3036, 'really really': 2190, 'great alternative': 1152, 'oreo': 1902, 'oreos': 1903, 'alternatives': 77, 'watchers': 2928, 'thin crisps': 2721, 'weight watchers': 2949, 'ladies': 1427, 'inches': 1330, 'across': 13, 'canola': 364, 'okay': 1852, 'dense': 678, 'late': 1439, 'spot': 2520, 'chocolatey': 450, 'appreciate': 113, 'pops': 2042, 'prevent': 2083, 'wise': 2986, 'cal': 345, 'spend': 2507, 'think would': 2727, 'would say': 3039, 'remind': 2233, 'considered': 540, 'sign': 2419, 'consuming': 549, 'besides': 206, 'free product': 1013, 'perfect size': 1983, 'traveling': 2796, 'comparable': 522, 'icing': 1318, 'trans': 2791, 'boost': 267, 'also make': 73, 'trans fat': 2792, 'like chips': 1474, 'opinion': 1890, 'according': 9, 'group': 1187, 'like chocolate': 1475, 'real thing': 2177, 'good even': 1110, 'sandwich': 2310, 'colored': 505, 'would give': 3024, 'thought would give': 2737, 'tomato': 2771, 'cooks': 571, 'yellow': 3059, 'rough': 2284, 'olive': 1857, 'savor': 2324, 'olive oil': 1858, 'half price': 1206, 'jam': 1370, 'kavli': 1383, 'experienced': 866, 'delicate': 669, 'love much': 1560, 'thinner': 2730, 'ordered case': 1900, 'tomatoes': 2772, 'via': 2891, 'bacon': 148, 'scissors': 2335, 'jelly': 1375, 'among': 89, 'toast': 2765, 'something different': 2480, 'flavor strong': 967, 'love taste': 1564, 'definitely buying': 665, 'currently': 626, 'oolong': 1885, 'belly': 202, 'sugar free': 2601, 'one thing': 1878, 'air tight': 51, 'whole box': 2970, 'slices': 2446, 'coconut oil': 489, 'muffin': 1714, 'hodgson': 1271, 'free products': 1014, 'muffin mix': 1715, 'hodgson mill': 1272, 'gluten free products': 1090, 'batter': 184, 'pamela': 1940, 'brownies': 314, 'brownie': 313, 'know not': 1415, 'positive': 2049, 'betty': 222, 'crocker': 610, 'look like': 1539, 'others tried': 1911, 'betty crocker': 223, 'cane': 359, 'measure': 1635, 'mix make': 1679, 'much like': 1711, 'brown sugar': 312, 'obviously': 1836, 'stumbled': 2590, 'apples': 112, 'calls': 350, 'thats': 2714, 'another reviewer': 96, 'carrots': 379, 'refund': 2219, 'something like': 2482, 'baking mix': 161, 'also made': 72, 'pancake': 1942, 'waffle': 2903, 'waffles': 2906, 'pancake waffle': 1944, 'waffle mix': 2905, 'pancake waffle mix': 1945, 'nature': 1728, 'gingerbread': 1073, 'jalapeno': 1369, 'much sugar': 1713, 'walnuts': 2913, 'convenience': 564, 'though not': 2734, 'choose': 456, 'expired': 869, 'impossible': 1326, 'batches': 183, 'belgian': 200, 'guilty': 1198, 'friends family': 1029, 'chips not': 439, 'baker': 159, 'directions': 710, 'potato bread': 2055, 'info': 1342, 'basic': 177, 'requires': 2243, 'not organic': 1806, 'yeast': 3058, 'crust': 616, 'one like': 1870, 'nice flavor': 1752, 'flavor great': 962, 'lay': 1443, 'tried different': 2803, 'european': 827, 'not order': 1805, 'powering': 2069, 'temperature': 2695, 'useful': 2867, 'specific': 2505, 'food good': 989, 'searched': 2343, 'better regular': 220, 'well packaged': 2952, 'low sodium': 1578, 'tuna': 2826, 'list ingredients': 1507, 'robust': 2277, 'sizes': 2439, 'shell': 2396, 'happy purchase': 1219, 'mountain': 1698, 'try flavors': 2817, 'tender': 2698, 'good buy': 1104, 'friendly': 1027, 'eat whole': 785, 'many times': 1615, 'shots': 2410, 'flavor good': 961, 'risk': 2271, 'coffee flavor': 494, 'coffee not': 498, 'high price': 1262, 'period': 1986, 'silky': 2420, 'best cup': 211, 'half half': 1205, 'community': 519, 'distinct': 728, 'great gift': 1158, 'vinegar': 2892, 'meet': 1639, 'shows': 2414, 'broke': 306, 'salt vinegar': 2302, 'many people': 1613, 'not happy': 1798, 'single serving': 2427, 'fluffy': 981, 'light fluffy': 1468, 'vinegar chips': 2893, 'salt vinegar chips': 2303, 'kettle': 1392, 'chips ever': 434, 'definitely order': 667, 'chips delicious': 433, 'chips great': 436, 'love chips': 1553, 'barbecue': 169, 'like hot': 1482, 'kettle chips': 1395, 'chips good': 435, 'best chips': 208, 'best chips ever': 209, 'hearty': 1242, 'oz bag': 1925, 'chips love': 437, 'no trans': 1768, 'discontinued': 716, 'keeping': 1387, 'wanted try': 2918, 'go ahead': 1093, 'fewer': 921, 'afterwards': 41, 'mid': 1656, 'definately': 662, 'chips really': 440, 'good no': 1115, 'no artificial': 1756, 'maple': 1617, 'behind': 199, 'wash': 2923, 'eyes': 874, 'maple syrup': 1618, 'cons': 538, 'pour': 2064, 'reviewer said': 2257, 'mass': 1624, 'kettle brand': 1393, 'addictive': 23, 'brand potato': 286, 'flavor really': 966, 'chips bag': 431, 'brand potato chips': 287, 'york': 3064, 'cheddar': 411, 'ruin': 2286, 'new york': 1745, 'brand chips': 285, 'vinegar flavor': 2894, 'potassium': 2053, 'not overpowering': 1808, 'tangy': 2653, 'sour cream': 2497, 'chips best': 432, 'importantly': 1325, 'barbeque': 170, 'balanced': 163, 'dijon': 705, 'honey dijon': 1282, 'kettle brand chips': 1394, 'sea salt vinegar': 2339, 'soaked': 2468, 'strong flavor': 2584, 'worse': 3011, 'addict': 20, 'happy find': 1218, 'bags chips': 155, 'tart': 2655, 'unpleasant': 2850, 'want try': 2916, 'replaced': 2239, 'loving': 1572, 'give stars': 1077, 'great deal': 1156, 'trans fats': 2793, 'quality food': 2141, 'worried': 3009, 'hopefully': 1285, 'starch': 2536, 'supplement': 2615, 'cane sugar': 360, 'tea good': 2685, 'like taste': 1493, 'cream onion': 603, 'bag chips': 151, 'sour cream onion': 2498, 'holes': 1275, 'great value': 1169, 'flavor no': 964, 'feels': 915, 'burned': 322, 'snob': 2466, 'worth money': 3015, 'england': 809, 'wondering': 2996, 'vary': 2882, 'rare': 2157, 'coupon': 591, 'serving size': 2380, 'select': 2361, 'flavor also': 960, 'first bag': 947, 'ridiculous': 2266, 'warehouse': 2921, 'damaged': 638, 'family favorite': 883, 'snow': 2467, 'typically': 2840, 'variety pack': 2880, 'cherry': 415, 'beer': 195, 'valley': 2874, 'holds': 1274, 'mark': 1620, 'ramen': 2153, 'pleasantly': 2018, 'pleasantly surprised': 2019, 'seconds': 2351, 'great crunch': 1155, 'flavors good': 973, 'breaking': 295, 'modified': 1684, 'dented': 679, 'spoiled': 2517, 'salmon': 2298, 'wild': 2980, 'tree': 2799, 'workout': 3004, 'peppermint': 1976, 'try something': 2819, 'occasion': 1837, 'coco': 485, 'includes': 1333, 'diagnosed celiac': 692, 'uncle': 2842, 'japanese': 1372, 'cajun': 341, 'could buy': 580, 'man': 1604, 'yesterday': 3061, 'much healthier': 1709, 'intolerant': 1359, 'gluten intolerant': 1091, 'severe': 2388, 'berry': 205, 'complain': 526, 'stands': 2532, 'strawberry': 2580, 'length': 1458, 'popped': 2039, 'kernels': 1390, 'sardines': 2312, 'free diet': 1011, 'gluten free diet': 1089, 'rip': 2270, 'free foods': 1012, 'raspberry': 2159, 'points': 2032, 'decided give try': 659, 'every month': 841, 'better tasting': 221, 'not enough': 1790, 'chowder': 459, 'clams': 469, 'not going': 1795, 'clam': 467, 'clam chowder': 468, 'gritty': 1180, 'watered': 2932, 'fillers': 927, 'used make': 2866, 'pricey': 2096, 'mug': 1717, 'cheapest': 408, 'product would': 2115, 'resealable': 2244, 'pomegranate': 2033, 'molasses': 1686, 'lamb': 1428, 'like flavor': 1479, 'cold water': 502, 'dirty': 712, 'canned food': 362, 'dry food': 765, 'breed': 297, 'caused': 390, 'equally': 820, 'adopted': 31, 'grain free': 1140, 'sampler': 2307, 'weak': 2940, 'smoother': 2460, 'tube': 2824, 'strawberries': 2579, 'bright': 303, 'dressings': 750, 'pear': 1970, 'plants': 2013, 'monthly': 1691, 'concentrate': 533, 'black licorice': 249, 'decaffeinated': 654, 'enjoying': 814, 'price reasonable': 2091, 'buttermilk': 327, 'pancake mix': 1943, 'healthy alternative': 1239, 'ages': 44, 'try one': 2818, 'dollar': 737, 'might not': 1659, 'popping': 2041, 'chocolate not': 448, 'one really': 1875, 'walmart': 2912, 'lb': 1445, 'lb bag': 1446, 'argentina': 115, 'pound bag': 2062, 'lasting': 1435, 'small bags': 2452, 'anti': 97, 'panda': 1948, 'comment': 514, 'closed': 476, 'definitely buy': 664, 'shiny': 2398, 'food dog': 988, 'dog foods': 732, 'alternative regular': 76, 'cat grass': 386, 'reaction': 2168, 'acidity': 12, 'marzano': 1623, 'san marzano': 2309, 'newman': 1746, 'organic dog': 1905, 'organic dog food': 1906, 'newman dog': 1747, 'smallest': 2454, 'two bags': 2833, 'harmony': 1226, 'harmony farms': 1227, 'turns': 2830, 'grey': 1176, 'organics': 1907, 'expensive brands': 864, 'really well': 2193, 'good enough': 1109, 'poured': 2065, 'tossed': 2783, 'get better': 1060, 'heavily': 1247, 'pay shipping': 1964, 'decaf coffee': 653, 'caribou': 375, 'tea powder': 2690, 'antioxidants': 98, 'water bottle': 2931, 'ease': 773, 'ounces water': 1915, 'japan': 1371, 'unsweetened': 2851, 'sports': 2519, 'juices': 1380, 'bottled': 272, 'sucralose': 2599, 'whim': 2964, 'weekend': 2945, 'not drink': 1788, 'flavors not': 976, 'pod': 2029, 'squeeze': 2527, 'plug': 2025, 'pods': 2030, 'writing': 3046, 'drinkers': 756, 'would give try': 3025, 'waffle maker': 2904, 'stonewall': 2565, 'pancakes waffles': 1947, 'pro': 2098, 'follow': 983, 'made pancakes': 1586, 'make pancakes': 1594, 'flavors like': 975, 'three flavors': 2739, 'good cup': 1107, 'creamer': 604, 'knob': 1413, 'audio': 132, 'recording': 2213, 'icicle': 1317, 'software': 2473, 'mic': 1652, 'plug play': 2026, 'usb': 2858, 'xlr': 3050, 'phantom': 1994, 'phantom power': 1995, 'cable': 336, 'condenser': 536, 'microphone': 1653, 'mics': 1655, 'olives': 1859, 'cup hot': 620, 'grape': 1146, 'gevalia': 1068, 'brewer': 300, 'coffee good': 495, 'melitta': 1640, 'smooth taste': 2459, 'drink coffee': 753, 'popchips': 2037, 'pop chips': 2036, 'love popchips': 1561, 'least favorite': 1452, 'regular potato': 2227, 'regular potato chips': 2228, 'assortment': 129, 'vita': 2897, 'vita coco': 2898, 'hot chocolate': 1290, 'tic': 2749, 'cup size': 623, 'swiss': 2637, 'lollipops': 1532, 'regular bisquick': 2225, 'popper': 2040, 'electrolytes': 800, 'coconut water': 490, 'gatorade': 1053, 'keurig': 1396, 'green mountain': 1173, 'kona': 1419, 'riviera': 2272, 'sunset': 2608, 'riviera sunset': 2273, 'french roast': 1019, 'keurig coffee': 1397, 'chocolate cups': 446, 'hulls': 1305, 'grove': 1188, 'free bisquick': 1010, 'gluten free bisquick': 1088, 'bisquick gluten': 238, 'bisquick gluten free': 239, 'key lime': 1399, 'lime pie': 1501, 'key lime pie': 1400, 'hot chocolates': 1292, 'swiss miss': 2638, 'grove square': 1189, 'cocoa cups': 487, 'hot chocolate cups': 1291, 'hot cocoa cups': 1294, 'kcup': 1384, 'artificial sweetener': 123, 'escapes': 821, 'cafe escapes': 339, 'mahogany': 1587, 'cup setting': 622, 'cup hot chocolate': 621, 'cup cocoa': 618, 'square hot': 2525, 'grove square hot': 1190, 'square hot cocoa': 2526, 'omaha': 1860, 'tassimo': 2656}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3kd5RwzJ1AK"
      },
      "source": [
        "# TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi43OQYBf0X7",
        "outputId": "c7e10f58-2c3e-4bfc-b268-11cb7a9ed706"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
        "tf_idf_vect.fit(preprocessed_reviews)\n",
        "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[0:10])\n",
        "print('='*50)\n",
        "\n",
        "final_tf_idf = tf_idf_vect.transform(preprocessed_reviews)\n",
        "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
        "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
        "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "some sample features(unique words in the corpus) ['ability', 'able', 'able find', 'able get', 'absolute', 'absolutely', 'absolutely delicious', 'absolutely love', 'absolutely no', 'according']\n",
            "==================================================\n",
            "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text TFIDF vectorizer  (4986, 3029)\n",
            "the number of unique words including both unigrams and bigrams  3029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98utXc2fLL9C"
      },
      "source": [
        "Info: Above we see the type of tf-idf-vector after fit_transform is a sparse matrix. Each row of the matrix is a particular review. Each column in row corresponds to the tf-idf value of particular feature /word . It is sparse because all the words form corpus will not be present in each review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X2SYGNkKmF1",
        "outputId": "8f5ff433-6b4b-4cba-b08a-78ff2fa32e11"
      },
      "source": [
        "# print the features names form 1000 to 1010 \n",
        "print(\"features names form 1000 to 1010\",tf_idf_vect.get_feature_names()[1000:1010]) \n",
        "features=tf_idf_vect.get_feature_names()\n",
        "print(\"Total Features size:\",len(features))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features names form 1000 to 1010 ['fragile', 'free', 'free bisquick', 'free diet', 'free foods', 'free product', 'free products', 'free shipping', 'freeze', 'freezer']\n",
            "Total Features size: 3029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WbCZE8mKrGQ",
        "outputId": "58110d53-2142-44a9-fb5f-016723eac771"
      },
      "source": [
        "# Get a vector corresponding to a review eg r3\n",
        "\n",
        "final_tf_idf[3,:].toarray() # row 3 all the columns \n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWtuCbsj76G4"
      },
      "source": [
        "# Get top n features related to a sentence/review \n",
        "\n",
        "def top_tfidf_feats(row, features, top_n=25):\n",
        "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
        "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
        "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
        "    df = pd.DataFrame(top_feats)\n",
        "    df.columns = ['feature', 'tfidf']\n",
        "    return df\n",
        "\n",
        "top_tf_idf=top_tfidf_feats(final_tf_idf[3,:].toarray()[0],features,25)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "rqCQl_iwDuCM",
        "outputId": "342188ea-8ffb-4e46-b213-5a87c03ffeff"
      },
      "source": [
        "print(preprocessed_reviews[3])\n",
        "top_tf_idf"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "really good idea final product outstanding use decals car window everybody asks bought decals made two thumbs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good idea</td>\n",
              "      <td>0.434395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outstanding</td>\n",
              "      <td>0.414054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>car</td>\n",
              "      <td>0.404419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>idea</td>\n",
              "      <td>0.326540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>really good</td>\n",
              "      <td>0.307497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>two</td>\n",
              "      <td>0.234951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>made</td>\n",
              "      <td>0.220373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bought</td>\n",
              "      <td>0.219595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>use</td>\n",
              "      <td>0.198740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>really</td>\n",
              "      <td>0.186046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>product</td>\n",
              "      <td>0.167144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>good</td>\n",
              "      <td>0.145212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>free foods</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>french</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>forward trying</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>freezer</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>freeze</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>free shipping</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>free products</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>free product</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>found</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>found amazon</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>free diet</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>frequently</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>free bisquick</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           feature     tfidf\n",
              "0        good idea  0.434395\n",
              "1      outstanding  0.414054\n",
              "2              car  0.404419\n",
              "3             idea  0.326540\n",
              "4      really good  0.307497\n",
              "5              two  0.234951\n",
              "6             made  0.220373\n",
              "7           bought  0.219595\n",
              "8              use  0.198740\n",
              "9           really  0.186046\n",
              "10         product  0.167144\n",
              "11            good  0.145212\n",
              "12      free foods  0.000000\n",
              "13          french  0.000000\n",
              "14  forward trying  0.000000\n",
              "15         freezer  0.000000\n",
              "16          freeze  0.000000\n",
              "17   free shipping  0.000000\n",
              "18   free products  0.000000\n",
              "19    free product  0.000000\n",
              "20           found  0.000000\n",
              "21    found amazon  0.000000\n",
              "22       free diet  0.000000\n",
              "23      frequently  0.000000\n",
              "24   free bisquick  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcvmkOm5IAm1",
        "outputId": "51509014-374f-426e-d99e-ec67edf96e48"
      },
      "source": [
        "#values of the finial_tf_idf shows it has the tfids values for few words and 0 for words that are not present in review\n",
        "final_tf_idf[3,:].toarray().reshape(233,13).tolist()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.21959490746847268,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.4044187591673645],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.14521173017839603,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.4343950081032161,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.3265400805879488],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.22037332490796274,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.41405411891193,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.16714405001748678],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.18604631759184379,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.3074969427711191,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.2349509506808951,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.19874040723154857,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw7--ntcFVYd",
        "outputId": "feb466d3-b13f-4b49-ac70-b42f100e2ce2"
      },
      "source": [
        "#sample to understand . As displayed above we are sorting the arguments that have top values of tfid's.\n",
        "#then we take the particular tf-idf values and find corresponding feature \n",
        "topn_ids = np.argsort(final_tf_idf[3,:].toarray()[0])[::-1][:25]\n",
        "print(\"Argument positions of top 25 ids\",topn_ids)\n",
        "print(\"Feature is : \",features[1100])\n",
        "print(\"TF-IDF value:\",final_tf_idf[3,:].toarray()[0][1100])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Argument positions of top 25 ids [1100 1891  363 1299 2156 2797 1560  273 2824 2153 2079 1090 1004 1010\n",
            "  995 1009 1008 1007 1006 1005  996  997 1003 1012 1002]\n",
            "Feature is :  good idea\n",
            "TF-IDF value: 0.4343950081032161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyEbtxaTlCa8"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQd0GUdyPbdF",
        "outputId": "ff2ce495-2bf0-45ce-b0dd-25a154ec1d22"
      },
      "source": [
        "print(\"Sample Review before split\",preprocessed_reviews[1])\n",
        "print(\"Sample Review after split\",preprocessed_reviews[1].split())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Review before split used victor fly bait seasons beat great product\n",
            "Sample Review after split ['used', 'victor', 'fly', 'bait', 'seasons', 'beat', 'great', 'product']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta9oR35ElXGG"
      },
      "source": [
        "# Train your own Word2Vec model using your own text corpus\n",
        "list_of_sentance=[]\n",
        "for sentance in preprocessed_reviews:\n",
        "    list_of_sentance.append(sentance.split())"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybdqf_YFl7ic",
        "outputId": "c0ac111f-9d9f-43f8-df4b-8a4da611332c"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_model=Word2Vec(list_of_sentance,min_count=5,size=50, workers=4) #Ignores all words with total frequency lower than 5.\n",
        "# size is the dimension of the vector that the word is converted into. \n",
        "# Words below the min_count frequency are dropped before training occurs. So, the relevant context window is the word-distance \n",
        "# among surviving words.\n",
        "# This de facto shrinking of contexts is usually a good thing: the infrequent words don't have enough varied examples to obtain \n",
        "# good vectors for themselves. Further, while individually each infrequent word is rare, in total there are lots of them, so these\n",
        "#  doomed-to-poor-vector rare-words intrude on most other words' training, serving as a sort of noise that makes those word-vectors\n",
        "#   worse too.\n",
        "\n",
        "# (Similarly, when using the sample parameter to down-sample frequent words, the frequent words are randomly dropped – which also \n",
        "# serves to essentially \"shrink\" the distances between surviving words, and often improves overall vector quality.)\n",
        "\n",
        "print(w2v_model.wv.most_similar('great'))\n",
        "print('='*50)\n",
        "print(w2v_model.wv.most_similar('worst'))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alternative', 0.9959698915481567), ('especially', 0.9957107305526733), ('tasty', 0.995488166809082), ('snack', 0.9954031109809875), ('excellent', 0.9949555397033691), ('though', 0.9948632717132568), ('anything', 0.9946957230567932), ('looking', 0.994658350944519), ('want', 0.9945265054702759), ('satisfying', 0.9945114254951477)]\n",
            "==================================================\n",
            "[('popcorn', 0.9993431568145752), ('clam', 0.9993214011192322), ('wife', 0.9993047714233398), ('dinner', 0.9992475509643555), ('looks', 0.9992450475692749), ('kinds', 0.9992398023605347), ('beef', 0.9991780519485474), ('cherry', 0.9991456270217896), ('blends', 0.9991450309753418), ('eaten', 0.999132513999939)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TkCqUfVmfV0",
        "outputId": "6d6d5380-dff3-4cb7-ee84-0282d5ab2556"
      },
      "source": [
        "w2v_words = list(w2v_model.wv.vocab)\n",
        "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
        "print(\"sample words \", w2v_words[0:20])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words that occured minimum 5 times  3816\n",
            "sample words  ['product', 'available', 'course', 'total', 'pretty', 'stinky', 'right', 'nearby', 'used', 'beat', 'great', 'received', 'shipment', 'could', 'hardly', 'wait', 'try', 'love', 'call', 'instead']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JfybdrZmow2",
        "outputId": "03ae7802-60c7-4c7e-b2c4-269f0c3dc9e5"
      },
      "source": [
        "#sample vector of a word \n",
        "w2v_model.wv.get_vector('great')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.20346636,  0.05142558, -0.07987118,  0.7056635 ,  0.13991535,\n",
              "       -0.58735245,  0.4888457 ,  0.11608417,  0.09917501, -0.04789089,\n",
              "        0.31361514, -0.20386474, -0.8633036 , -0.28058898,  0.1339536 ,\n",
              "       -0.40925926, -0.64469117, -0.60524803,  0.13972339,  0.8648939 ,\n",
              "        0.3203178 , -0.11666155,  0.08422046, -0.05454169,  0.6045814 ,\n",
              "        0.09204479, -0.38339922, -0.34347633,  0.15345779, -0.33865762,\n",
              "       -0.01031807, -0.66409236,  0.11144474, -0.1375475 , -0.12502065,\n",
              "        0.59884524, -0.3973102 , -0.21236809, -0.61564946,  0.22381188,\n",
              "       -0.7147021 , -0.5384901 ,  0.3423769 , -0.60778314, -0.6377711 ,\n",
              "       -0.06028188,  0.31933197,  0.37180412, -0.92168146, -0.6415185 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ahgVXEQmGp"
      },
      "source": [
        "# Avg Word2Vec - continuation of w2v (w2v model is needed before this)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMem2FUuoT79",
        "outputId": "ce5d3987-7429-4525-cc63-780c15e8fbbb"
      },
      "source": [
        "# Instead of computing vector for each word how to compute one vector for each sentence/Review?? \n",
        "#Sum all the vectors of the words present in review, divide by the total number of words present in that review. AvgW2Vec\n",
        "# list_of_sentance contains list of reviews and each review split on space to have words for that review\n",
        "\n",
        "# average Word2Vec\n",
        "# compute average word2vec for each review.\n",
        "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
        "for sent in tqdm(list_of_sentance): # for each review/sentence\n",
        "    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n",
        "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
        "    for word in sent: # for each word in a review/sentence\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "    if cnt_words != 0:\n",
        "        sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)\n",
        "print(len(sent_vectors))\n",
        "print(len(sent_vectors[0]))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4986/4986 [00:04<00:00, 1028.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4986\n",
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxqyObfyYDMJ"
      },
      "source": [
        "TFIDF weighted W2v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuma8oP8YTfH"
      },
      "source": [
        "# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\n",
        "model = TfidfVectorizer()\n",
        "model.fit(preprocessed_reviews)\n",
        "# we are converting a dictionary with word as a key, and the idf as a value\n",
        "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06tesVIHSKuR",
        "outputId": "abf1df11-d70e-456e-e831-75b30ad906de"
      },
      "source": [
        "# TF-IDF weighted Word2Vec\n",
        "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
        "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
        "\n",
        "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
        "row=0;\n",
        "for sent in tqdm(list_of_sentance): # for each review/sentence \n",
        "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
        "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
        "    for word in sent: # for each word in a review/sentence\n",
        "        if word in w2v_words and word in tfidf_feat:\n",
        "            vec = w2v_model.wv[word]\n",
        "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
        "            # to reduce the computation we are \n",
        "            # dictionary[word] = idf value of word in whole courpus\n",
        "            # sent.count(word) = tf valeus of word in this review\n",
        "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
        "            sent_vec += (vec * tf_idf)\n",
        "            weight_sum += tf_idf\n",
        "    if weight_sum != 0:\n",
        "        sent_vec /= weight_sum\n",
        "    tfidf_sent_vectors.append(sent_vec)\n",
        "    row += 1"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4986/4986 [00:36<00:00, 136.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
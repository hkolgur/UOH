{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_tweet_Sentiment_Bert_As_Embedding_only.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNM93Mi+7M8jUlCviBPWlUQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkolgur/UOH/blob/main/BERT_tweet_Sentiment_Bert_As_Embedding_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0RM8owwQCIx"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vAgf8nGL8LR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import re \n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from google.colab import drive\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJkzOI6SNb3U"
      },
      "source": [
        "### Imports related to BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0beaRAK5NCiF",
        "outputId": "1e24556c-6e02-4ea4-ca6e-279dbcbfbaf6"
      },
      "source": [
        "!pip install bert-for-tf2  #tensorflow2 \n",
        "!pip install sentencepiece #bert-for-tf2 need for decode"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 23.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=348520f07c1a4ed7aadfee795d633a3284cc54aef741f59ce56217218744edbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=4a81d08055c3c04666700e0de0d2e0d04c8440ec6cb21a2582b7ccd051cc13f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=65bc2be739ca1000216011c9a0f10e7cd84c7a981b1390e7145b8f2e40355460\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfM2IXbQOtHj"
      },
      "source": [
        "import tensorflow as tf #tensor flow version is 2.x + \n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbw3-PIQTj9"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-jc-9YwQcVd",
        "outputId": "5efe06f8-45b5-4af1-acef-2e76dbca737f"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jiFoFh7WzzZ"
      },
      "source": [
        "cols=['sentiment','id','date','query','user','text']\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/UOH/stanford-twitter/t55.csv\",\n",
        "               names=cols,\n",
        "               header=None,\n",
        "               engine=\"python\",\n",
        "              # sep='delimiter',\n",
        "               encoding=\"latin1\")\n",
        "\n",
        "\n",
        "#Keep label and text . Drop other columns\n",
        "df.drop(['id','date','query','user'],axis=1,inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB9OsQyXe5tv",
        "outputId": "f29afa94-31c3-4ff8-994d-b1225772645a"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4893\n",
              "4    3623\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smlvCGrCuqfS"
      },
      "source": [
        "# Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xp4me1CSuuUS",
        "outputId": "22432981-92a6-45c9-d0e4-04a35b79bc99"
      },
      "source": [
        "df['text'][1]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmGweZRdu2_3"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "  tweet=BeautifulSoup(tweet,\"lxml\").get_text() #get english format text form the input that is in lxml format \n",
        "  tweet=re.sub(r'@[A-za-z0-9]+','',tweet) # Remove @name\n",
        "  tweet=re.sub(r'https?://[A-Za-z0-9./]+',' ',tweet) #remove http or https links \n",
        "  tweet=re.sub(r'[^a-zA-Z0-9.!?\\']',' ',tweet) # Only keep alpha,num,punctuations \n",
        "  tweet=re.sub(r' +',' ',tweet)  #replace more than one space with single space\n",
        "  return tweet\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lfGNrtz145F",
        "outputId": "cab255cf-10b8-44a2-c481-db8389a9bc4a"
      },
      "source": [
        "#Sample test to check how clean_tweet is working \n",
        "print(\"Before Cleaning:\\n\",df['text'][0])\n",
        "t=clean_tweet(df['text'][0])\n",
        "print(\"After Cleaning:\\n\",t)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Cleaning:\n",
            " @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
            "After Cleaning:\n",
            "  Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60DfIa4uv3fL"
      },
      "source": [
        "#clean text for the whole data frame \n",
        "data_clean=[clean_tweet(x)for x in df['text']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huq1HVT2yYeO"
      },
      "source": [
        "#separate the label colum form data frame\n",
        "data_label=df.sentiment\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc5eyOUZ3vWS",
        "outputId": "80ec0abb-1d0c-4b5e-a920-8f5fdcec990f"
      },
      "source": [
        "#change the data label 4 to 1 to mark as positve or 0 for negative review\n",
        "data_label[data_label==4]=1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FAAVUY8VqBj",
        "outputId": "0bd44c29-9ea0-4159-89f5-5a845d8eccd2"
      },
      "source": [
        "data_label.value_counts()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4893\n",
              "1    3623\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ktj7KJ76kjb"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvyWL9dJ6w7V"
      },
      "source": [
        "##### Use tokenization tool from BERT  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZLAwbW46mdr"
      },
      "source": [
        "FullTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "\n",
        "#Create bert layer because there is information about tokenizer in it .\n",
        "#pre-trained models are stored in tensor flow hub. From there we try to get the weights\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False) # Because we just want to use it for tokenization\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apkUTxXl927Z"
      },
      "source": [
        "#Get vocab file for the tokenizer \n",
        "vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()  \n",
        "#lowercasing the text or not \n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "tokenizer=FullTokenizer(vocab_file,do_lower_case)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weoSQFxkAqFc",
        "outputId": "d8690d06-58b6-4177-8593-1dbd0139bc74"
      },
      "source": [
        "#sample tokenizer of a sentence \n",
        "print(tokenizer.tokenize(\"I love cherries\"))\n",
        "# Get the token ids for each of the token \n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"I love cherries\")))\n",
        "#convert id  16138 to token\n",
        "print(tokenizer.convert_ids_to_tokens([16138]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'love', 'che', '##rries']\n",
            "[146, 16138, 10262, 107788]\n",
            "['love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td-FHmXfAvUf"
      },
      "source": [
        "# #Apply tokenizer to each sentence of data_clean\n",
        "# def encode_sentence(sentence):\n",
        "#   return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkqdW1X64Xhr"
      },
      "source": [
        "#New encode sentence format to suit it as input to BERT layer\n",
        "def encode_sentence(sentence):\n",
        "    return [\"[CLS]\"] + tokenizer.tokenize(sentence) + [\"[SEP]\"]  "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQQuOEu9COLS"
      },
      "source": [
        "data_inputs=[encode_sentence(sent) for sent in data_clean]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGtoJo77Dnl1",
        "outputId": "d518d0c3-3a43-4f8b-a723-86f56651ada0"
      },
      "source": [
        "# Here is how sample data_input looks like with tokens \n",
        "data_inputs[1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'is',\n",
              " 'upset',\n",
              " 'that',\n",
              " 'he',\n",
              " 'can',\n",
              " \"'\",\n",
              " 't',\n",
              " 'update',\n",
              " 'his',\n",
              " 'Facebook',\n",
              " 'by',\n",
              " 'text',\n",
              " '##ing',\n",
              " 'it',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " 'and',\n",
              " 'might',\n",
              " 'c',\n",
              " '##ry',\n",
              " 'as',\n",
              " 'a',\n",
              " 'result',\n",
              " 'School',\n",
              " 'today',\n",
              " 'also',\n",
              " '.',\n",
              " 'B',\n",
              " '##lah',\n",
              " '!',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTBWMIIWECpJ"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GveLIS0H57vK"
      },
      "source": [
        "### we need to create 3 differnt inputs for each sentence (tokenized sentence with cls and sep added , list of mask (where aer padding values) , segment input ( seq of 1 /0 - 0 indicate we are in first sentence and 1 indiciate we are in second sentence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq9aX7Uq6p8p"
      },
      "source": [
        "# GET WORD VECTOR FROM A LIST OF TOKENS\n",
        "#sample input: ['[CLS]', 'That', '##s', 'messe', '##d', 'up', '[SEP]']\n",
        "def get_ids(tokens):\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# Check if  TOKENS HAVE [PAD] PADDING OR NOT\n",
        "# NOTE: In this case it is not important but we will use it to maintain general norm\n",
        "#sample input: ['[CLS]', 'That', '##s', 'messe', '##d', 'up', '[SEP]']\n",
        "def get_mask(tokens):\n",
        "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
        "\n",
        "#Get ID of Segments \n",
        "#sample input: ['[CLS]', 'That', '##s', 'messe', '##d', 'up', '[SEP]']\n",
        "def get_segments(tokens):\n",
        "    seg_ids = []\n",
        "    current_seg_id = 0\n",
        "    for tok in tokens:\n",
        "        seg_ids.append(current_seg_id)\n",
        "        if tok == \"[SEP]\":\n",
        "            current_seg_id = 1-current_seg_id # turns 1 into 0 and vice versa\n",
        "    return seg_ids\n",
        "  "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h1uin4I1bFR"
      },
      "source": [
        "### We will create padded batches (so we pad sentences for each batch independently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXwJufduEFIn"
      },
      "source": [
        "#we need to pad the sentences to be of same length while training. To do this we can use below techinique\n",
        "#we can train in batches and sentences in each batch has to be of same length (apply padding).But all the sentences in \n",
        "#all the batches need not be of same lenght. \n",
        "\n",
        "#We can split the sentences from input based on their lenghts so that we need not apply much padding when we group them into \n",
        "#batches.\n",
        "data_with_len=[[sent_token,data_label[i],len(sent_token)] for i,sent_token in enumerate(data_inputs)]\n",
        "\n",
        "#now in our original data we had all labels of 0 together and 1 at end. so lets shuffle data to get a mix\n",
        "random.shuffle(data_with_len)\n",
        "\n",
        "#Sort data based on len(sent_token)\n",
        "data_with_len.sort(key=lambda x:x[2]) # x will have sent_token,data_label[i],len(sent_token) \n",
        "# Data with len is list of lists like:\n",
        "#[[['[CLS]', 'That', '##s', 'messe', '##d', 'up', '[SEP]'], 0, 7],\n",
        "# [['[CLS]', 'Thank', '##s', 'for', 'that', '.', '[SEP]'], 1, 7]]\n",
        "# Above each list item has the first element as a list with cls token sep , second item as label third item as length\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLATyitXNfsg"
      },
      "source": [
        "#Next drop the len(sent_token) and also keep only the sentence tokens that have a lenght of >7 . This is to make sure we have\n",
        "#longer senternces to convery meaning. If sentence length was <7 then it may not convey much meaning. \n",
        "#7 is arbitary choose your own lenght you think is most precise\n",
        "\n",
        "sorted_all=[(\n",
        "    [get_ids(x[0]),\n",
        "    get_mask(x[0]),\n",
        "    get_segments(x[0])],\n",
        "    x[1]) for x in data_with_len if x[2]>7] #storing as a tuple\n",
        "\n",
        "#[(ids[],maks[],segmentids[])],[labels]\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAIT4Y8vNj0a"
      },
      "source": [
        "#Usually we use the  from tensor methods/tensor slices etc to create a dataset .Here we cannot use that because all \n",
        "#sentences are of not same lenght.\n",
        "#So we need to call the from_generator . Creates a Dataset whose elements are generated by generator.\n",
        "#List is a generator so we can use above list  to create a dataset form generator \n",
        " \n",
        "all_dataset=tf.data.Dataset.from_generator(lambda : sorted_all,output_types=(tf.int32, tf.int32))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EOKpbkJxoeV",
        "outputId": "5688cfb8-dbb2-4664-e58c-c783e82886fe"
      },
      "source": [
        "#check element of all_dataset\n",
        "next(iter(all_dataset))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
              " array([[  101, 11084, 10174, 13028, 10142, 10105, 62975,   102],\n",
              "        [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn2w0Z-L3atL"
      },
      "source": [
        "BATCH_SIZE=32\n",
        "#Padded_batch takes size of the batch and the padded_shapes\n",
        "#Dimensions  used for padding are indicated with None,dim corresponding to real value if inputs\n",
        "# (first ele of tuple corresponds to the input) \n",
        "#labels will be batched according to the batch size of input if we leave it as blank () to indicate zero dim tensor\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((3,None, ), ()),padding_values=(0, 0))\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUjzRa8Ar9j"
      },
      "source": [
        "### Create a testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuD4a9giAq4_"
      },
      "source": [
        "# divide size of data /batch_size to get number of batches\n",
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "\n",
        "# Form the number of batches take 10% as Test batches\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10 \n",
        "\n",
        "#Shuffle all_batced data because we have shortest sentences at the beginning and longest at the end \n",
        "#If we dont shuffle ,all small sizes batches data will be alloted to test longer sentences end up in trainng \n",
        "#shuffle takes buffer size as input . IF data set is not too big give buffer size = batch_size\n",
        "\n",
        "all_batched.shuffle(NB_BATCHES) \n",
        "\n",
        "#take method which allows to take first n number \n",
        "# take 10% of batches to test \n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST) \n",
        "# take 90% of data to train data set\n",
        "#skip skips n number\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST) "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CH1iMewCTYh",
        "outputId": "d57224db-b319-4b53-a0a1-c062740ecab5"
      },
      "source": [
        "print(\"Total Batches:\",NB_BATCHES)\n",
        "print(\"Total Test Batches:\",NB_BATCHES_TEST)\n",
        "print(\"Total Train Batches:\",NB_BATCHES-NB_BATCHES_TEST)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Batches: 247\n",
            "Total Test Batches: 24\n",
            "Total Train Batches: 223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmzUm3zaEj3m"
      },
      "source": [
        "# Model Building "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rdq-_Sl8VuO",
        "outputId": "d5ba0cd0-ddf1-4e1d-92af-5b7c3c2b19c7"
      },
      "source": [
        "# Test code to check what we  get when we call a  Bert Layer\n",
        "my_sent=[\"[CLS]\"] + tokenizer.tokenize(\"This is good to see\") + [\"[SEP]\"] # this is the format of sentence A\n",
        "\n",
        "#create 3 differnt types of tokens(tensors and simulate like a batch) of inputs then call bert layer\n",
        "\n",
        "# first arg is to simulate a batch with input as tensor,cast it to int and  simulate batch along first dim 0\n",
        "bert_layer([tf.expand_dims(tf.cast(get_ids(my_sent),tf.int32),0), \n",
        "            tf.expand_dims(tf.cast(get_mask(my_sent),tf.int32),0),\n",
        "            tf.expand_dims(tf.cast(get_segments(my_sent),tf.int32),0)])\n",
        "            \n",
        "#output:\n",
        "#The input is made of 2 elemetns the first one is a tensor of shape 1,768 - 1- for simulated batch 768 for hidden dims\n",
        "#second element is tensor of shape (1,7,768) -1-for simulated batch ,7-for tokens in inputs(cls,sent,sep) and 768 for hidden dim \n",
        "\n",
        "#so each time we have these 2 outputs if cls task use firt output , else to go to  token level of specification ,\n",
        "# which we want to do now in this task to use bert as embedder. for each word/token we get a vector \n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[ 0.32685918, -0.0878264 ,  0.38913628, -0.22595926, -0.14458975,\n",
              "          0.545284  ,  0.30522987,  0.24586181, -0.50160766,  0.36522722,\n",
              "          0.00836129, -0.2676508 , -0.22702737, -0.1438212 ,  0.14432485,\n",
              "         -0.13008605,  0.7506511 ,  0.12150548,  0.19158159, -0.3550185 ,\n",
              "         -0.99991184, -0.15698163, -0.4492925 , -0.19456938, -0.35273194,\n",
              "          0.13880508, -0.22038977,  0.26147228,  0.2627607 , -0.16515788,\n",
              "          0.22825648, -0.99991405,  0.6173775 ,  0.762883  ,  0.29918417,\n",
              "         -0.24160737,  0.30260637,  0.26335764,  0.33180252, -0.29963297,\n",
              "         -0.05847782,  0.05625503, -0.10038682,  0.04993977, -0.0599305 ,\n",
              "         -0.35278335, -0.17938833,  0.23497139, -0.39601618,  0.12681796,\n",
              "         -0.00395847,  0.1588027 ,  0.63745534,  0.23118608,  0.316901  ,\n",
              "          0.20020404,  0.17543592,  0.25016633,  0.34923348, -0.25404814,\n",
              "         -0.0087584 ,  0.3622237 ,  0.18640594, -0.1710084 , -0.40927872,\n",
              "         -0.27392694,  0.10073924, -0.06257872,  0.5896809 , -0.3314693 ,\n",
              "         -0.3327471 , -0.49210736, -0.28614664,  0.08374064,  0.13661548,\n",
              "         -0.4052074 ,  0.33225283,  0.24967124,  0.10253707, -0.17936152,\n",
              "         -0.48316336, -0.57503456, -0.39372176,  0.28316745, -0.21487555,\n",
              "          0.32245412,  0.2710044 , -0.5338635 ,  0.12090574,  0.05086124,\n",
              "          0.27845636,  0.6192522 , -0.229964  ,  0.39443335, -0.18602015,\n",
              "         -0.24505493, -0.89148784, -0.13120243, -0.31360003, -0.527255  ,\n",
              "         -0.2565827 ,  0.25457096, -0.30709   , -0.15753287, -0.3420709 ,\n",
              "         -0.40560988,  0.08970393,  0.25744316, -0.14670528,  0.23279506,\n",
              "          0.14973967, -0.5191155 , -0.19024968,  0.16189931, -0.3561428 ,\n",
              "          0.9893058 , -0.39503974,  0.2419389 , -0.07668655, -0.17128259,\n",
              "         -0.6310994 ,  0.9999138 ,  0.2256103 , -0.21799007,  0.10066231,\n",
              "          0.30809125, -0.44443318,  0.21396063,  0.36620644,  0.4265591 ,\n",
              "          0.22654551, -0.18472129, -0.09484341, -0.44514328, -0.8773067 ,\n",
              "         -0.28220373, -0.29079613,  0.41133854, -0.41794062, -0.06726228,\n",
              "          0.23834386,  0.5920946 ,  0.09510628, -0.04661992, -0.09911098,\n",
              "         -0.07847957,  0.30124712, -0.1447179 ,  0.9999013 ,  0.7438238 ,\n",
              "         -0.32477552, -0.24239187,  0.578744  , -0.7492228 , -0.325794  ,\n",
              "         -0.30373037, -0.43700638, -0.6458759 ,  0.16730729,  0.24274433,\n",
              "          0.1337247 , -0.13852215, -0.1594732 , -0.27552038,  0.38341603,\n",
              "         -0.6829284 , -0.24258214,  0.2036095 ,  0.35806692,  0.33845985,\n",
              "         -0.328492  ,  0.3478349 ,  0.08450806, -0.39036855, -0.24615943,\n",
              "          0.2486089 ,  0.24751143,  0.02491601, -0.20088182, -0.1634604 ,\n",
              "          0.23792896, -0.2597266 , -0.4580226 ,  0.20936148, -0.21076657,\n",
              "         -0.5059247 ,  0.21111292,  0.10017845, -0.20354326,  0.1588197 ,\n",
              "         -0.21690452,  0.20585756, -0.337612  ,  0.2825577 ,  0.2825092 ,\n",
              "          0.12059495, -0.46913442,  0.26342347,  0.3750081 ,  0.23648144,\n",
              "          0.22687636,  0.17453061,  0.1698962 ,  0.21618989, -0.22578706,\n",
              "         -0.66967356,  0.43600115,  0.10799611,  0.45011616, -0.20526662,\n",
              "         -0.47808388, -0.3832722 ,  0.61833256,  0.38207397, -0.27961656,\n",
              "          0.35336173,  0.31054425, -0.30329594, -0.16648051,  0.17889811,\n",
              "         -0.15564308, -0.34257695, -0.31324217, -0.46260676, -0.01020968,\n",
              "          0.31490418,  0.09018979,  0.30017996,  0.18991919, -0.10855984,\n",
              "         -0.24372417, -0.08812038,  0.11504033,  0.35384795, -0.17496845,\n",
              "          0.902482  , -0.28974617,  0.14295354, -0.6178311 , -0.01626324,\n",
              "          0.36913827, -0.07485855,  0.29710045,  0.9803393 ,  0.22653688,\n",
              "         -0.38882938,  0.412099  ,  0.2878742 ,  0.11767622, -0.22302355,\n",
              "         -0.00822202, -0.6274802 ,  0.70511115,  0.40537313,  0.27004814,\n",
              "         -0.9999101 ,  0.22531219,  0.222277  ,  0.47713703,  0.27177602,\n",
              "          0.30116218,  0.30492255,  0.16969258,  0.9526342 , -0.48039824,\n",
              "         -0.5844188 , -0.39014542, -0.15453058, -0.6728496 , -0.264295  ,\n",
              "         -0.24279368, -0.2762922 , -0.2621747 , -0.14916177, -0.16265863,\n",
              "          0.24975401,  0.30672386, -0.9974292 ,  0.92129433,  0.00649921,\n",
              "         -0.19223772,  0.0485559 ,  0.21118945, -0.9999246 ,  0.35261175,\n",
              "         -0.10245595, -0.44038332,  0.37119612, -0.52894443, -0.38028753,\n",
              "          0.24754634,  0.51787966,  0.35186377,  0.21831909,  0.18261872,\n",
              "          0.5828823 , -0.18381037,  0.06392077,  0.24039961, -0.05061479,\n",
              "          0.68905574,  0.04209734,  0.09079012,  0.34378386, -0.13488528,\n",
              "          0.4259146 , -0.25597233,  0.46275923,  0.4316979 ,  0.18076123,\n",
              "          0.08605636, -0.25667387,  0.38957196, -0.81622225,  0.23162656,\n",
              "         -0.26881546, -0.27052665, -0.02869986,  0.17170267, -0.3693712 ,\n",
              "         -0.26169917,  0.19819233, -0.41134667,  0.99992144,  0.14292164,\n",
              "         -0.28756294, -0.34739736,  0.5248291 ,  0.5402182 , -0.393295  ,\n",
              "         -0.71396375, -0.21929292,  0.66291624,  0.47321516,  0.22387452,\n",
              "          0.09268559, -0.07512121,  0.1665542 , -0.22335525, -0.15043308,\n",
              "          0.19215643, -0.47993287,  0.22623593, -0.06711846, -0.5241612 ,\n",
              "          0.05325609, -0.2561123 , -0.17787074, -0.77965593,  0.29107425,\n",
              "          0.14220878,  0.2717167 ,  0.19168577, -0.00119738, -0.3121946 ,\n",
              "          0.65217954,  0.447995  , -0.2088567 , -0.25978097, -0.2819629 ,\n",
              "         -0.24791715,  0.06130143, -0.27509227, -0.38798705,  0.14085747,\n",
              "         -0.7316665 ,  0.09784803, -0.03742205, -0.32265133, -0.3165944 ,\n",
              "          0.31493574, -0.99993205, -0.25046456,  0.25501812, -0.33764172,\n",
              "          0.2494884 , -0.39004526, -0.22362217,  0.2412366 ,  0.17611328,\n",
              "         -0.01885128,  0.19700946, -0.49332318,  0.19048025, -0.06583547,\n",
              "          0.16365126,  0.8680328 ,  0.7041376 ,  0.18300487, -0.29300737,\n",
              "          0.16458826, -0.5852285 , -0.33662382,  0.3406143 ,  0.31934252,\n",
              "         -0.08534601,  0.27362707,  0.3142742 ,  0.16178049, -0.33960232,\n",
              "          0.3203508 , -0.11239273, -0.23612194,  0.40247604, -0.03697056,\n",
              "         -0.21923028, -0.33353746,  0.31567737, -0.54303443,  0.3924927 ,\n",
              "         -0.05823165,  0.38005248,  0.1124373 ,  0.49582988, -0.4491488 ,\n",
              "         -0.20427415, -0.05136258,  0.09060749, -0.43832046, -0.19863363,\n",
              "         -0.18993025,  0.99991244,  0.34075978,  0.37455213, -0.40829536,\n",
              "          0.16234599,  0.46429577, -0.2820379 ,  0.33829662,  0.2527825 ,\n",
              "          0.24091665, -0.09689716,  0.11010077,  0.16401608,  0.40095088,\n",
              "          0.3530018 ,  0.30679518,  0.52887917, -0.41333014,  0.7202314 ,\n",
              "         -0.3603295 , -0.4544793 , -0.9980713 ,  0.21620025,  0.48664954,\n",
              "         -0.42590258, -0.7013472 ,  0.1635317 , -0.3815613 ,  0.20948756,\n",
              "         -0.31480488,  0.11925914,  0.33420452, -0.26601258,  0.38333917,\n",
              "         -0.22274634,  0.9999237 , -0.2527348 ,  0.04633362,  0.32440487,\n",
              "          0.3795174 , -0.3613853 , -0.23020872, -0.24358128,  0.27212012,\n",
              "         -0.13293156,  0.3057247 , -0.9639758 ,  0.16357674,  0.1951236 ,\n",
              "          0.39040226, -0.1513467 ,  0.29529706, -0.5590251 ,  0.35116974,\n",
              "          0.00881802, -0.16725306, -0.41017756,  0.4025914 , -0.51135737,\n",
              "          0.5959249 , -0.2191051 ,  0.15758818, -0.42709255,  0.3216164 ,\n",
              "         -0.21325219,  0.3390924 , -0.23172484,  0.1331988 , -0.23151338,\n",
              "         -0.29522333, -0.2986946 ,  0.20351084, -0.43626004,  0.99991655,\n",
              "         -0.06746446,  0.3992694 , -0.20499219,  0.3130958 , -0.3229274 ,\n",
              "          0.44436148,  0.7638067 , -0.34295067,  0.05936345,  0.17833592,\n",
              "         -0.8184017 ,  0.4402339 , -0.06384546, -0.77286446, -0.21671961,\n",
              "          0.9763459 ,  0.16247047,  0.53032964,  0.62074   ,  0.39978597,\n",
              "          0.29358023, -0.2738545 ,  0.32189715,  0.8907114 ,  0.09380594,\n",
              "          0.3091944 ,  0.19613469, -0.14021164, -0.40434968, -0.372912  ,\n",
              "          0.9999189 ,  0.99990195,  0.07610665,  0.3381463 , -0.19973238,\n",
              "         -0.30350804, -0.2750316 ,  0.3116892 ,  0.2565137 ,  0.29287645,\n",
              "          0.06086244,  0.07299628, -0.45041722, -0.3064003 , -0.17234258,\n",
              "         -0.13012229, -0.25477415,  0.11573201, -0.35753042,  0.58921534,\n",
              "          0.47843963,  0.17880683,  0.634991  ,  0.28041676,  0.28456327,\n",
              "         -0.02620049, -0.2378537 ,  0.49715772, -0.30681217, -0.14478338,\n",
              "         -0.44477803,  0.15918767, -0.99990445, -0.29182526, -0.17805976,\n",
              "         -0.37000573,  0.5880418 ,  0.20004247,  0.21227844, -0.39491904,\n",
              "         -0.10927547, -0.3919769 ,  0.29975677,  0.27781662,  0.19251116,\n",
              "         -0.10468936, -0.3906301 ,  0.4628076 , -0.48988092,  0.19305114,\n",
              "         -0.21050084, -0.31156138, -0.6966982 , -0.1879831 , -0.4441733 ,\n",
              "          0.35672963, -0.40049493, -0.39166945,  0.27474427,  0.36117798,\n",
              "          0.47910208, -0.42377985,  0.33346805, -0.2544788 ,  0.11424147,\n",
              "          0.44083562,  0.32687053,  0.37566912, -0.3039977 , -0.2750449 ,\n",
              "         -0.17932524, -0.32533365, -0.18924816,  0.3780873 , -0.33768493,\n",
              "          0.28638077, -0.20442018,  0.17673148, -0.2166842 ,  0.2179329 ,\n",
              "          0.2522774 ,  0.39409742, -0.3061425 ,  0.5513917 ,  0.4795403 ,\n",
              "         -0.10784447,  0.52008164,  0.19183044, -0.36813214, -0.250222  ,\n",
              "          0.99993294,  0.4573763 ,  0.24598673,  0.34226754, -0.10750511,\n",
              "          0.39862216,  0.0595443 ,  0.55474913, -0.1990339 ,  0.80512404,\n",
              "         -0.31797624,  0.2122719 ,  0.19234872,  0.41319793,  0.3242523 ,\n",
              "          0.22719623,  0.37664357,  0.8139869 ,  0.40615636,  0.30305815,\n",
              "          0.37385708,  0.4322831 ,  0.31203625,  0.3994615 ,  0.1401119 ,\n",
              "          0.47767207,  0.32342094, -0.27575272,  0.40625325, -0.21628778,\n",
              "         -0.2822791 , -0.07403138, -0.15539204, -0.26748577,  0.23942684,\n",
              "         -0.17726962, -0.2489258 , -0.25153437,  0.3338257 , -0.08974617,\n",
              "          0.2126798 , -0.17676368, -0.41141427,  0.6119008 , -0.54926497,\n",
              "          0.2287262 , -0.16358806,  0.09004336, -0.8743103 ,  0.1583955 ,\n",
              "         -0.15946911, -0.5272131 , -0.34092736, -0.5160741 ,  0.16595319,\n",
              "          0.36441576, -0.0801562 ,  0.28047734, -0.33109668,  0.30527213,\n",
              "         -0.31682134, -0.2345338 ,  0.20015678, -0.9999275 ,  0.11755677,\n",
              "          0.07111392, -0.49634823,  0.06149695, -0.01334355,  0.2876316 ,\n",
              "          0.418013  , -0.42559287, -0.27394074, -0.10022231,  0.27889824,\n",
              "         -0.17144673,  0.00403326,  0.27376932, -0.45871025, -0.19139847,\n",
              "          0.10360038, -0.20196062,  0.18645371,  0.28783885, -0.38921332,\n",
              "          0.2515522 , -0.27814126,  0.18378273, -0.2270941 ,  0.3254431 ,\n",
              "         -0.32956108, -0.3893952 ,  0.2905812 , -0.47939345, -0.39743042,\n",
              "         -0.17876732,  0.17962362, -0.24587998,  0.3179604 ,  0.139275  ,\n",
              "         -0.16969286,  0.4469624 , -0.24494493,  0.3328696 , -0.29791087,\n",
              "          0.30598718, -0.8830487 , -0.4011132 , -0.48924154, -0.16952725,\n",
              "          0.3715077 ,  0.38440335,  0.16756615,  0.28538743, -0.10988459,\n",
              "          0.21686728, -0.1576211 ,  0.40334776,  0.14892654, -0.2101659 ,\n",
              "         -0.01688347, -0.2870249 ,  0.32926473, -0.4020556 ,  0.01876927,\n",
              "         -0.9962846 , -0.3831404 ,  0.08919416,  0.3050145 ,  0.4225265 ,\n",
              "         -0.31125036, -0.10905647, -0.45132983, -0.22937927,  0.3190091 ,\n",
              "          0.26715323,  0.42055815,  0.32159647,  0.19627781, -0.22328265,\n",
              "         -0.01197092,  0.7358808 , -0.36828062,  0.00215231,  0.5064367 ,\n",
              "          0.14371486,  0.8503671 ,  0.3478666 ,  0.42786574,  0.22973788,\n",
              "         -0.35822096,  0.371879  ,  0.48198715]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 7, 768), dtype=float32, numpy=\n",
              " array([[[ 2.35007048e-01, -4.46288176e-02,  2.13497996e-01, ...,\n",
              "           3.22475463e-01, -1.40444130e-01,  1.73592925e-01],\n",
              "         [-8.20318311e-02, -3.09061408e-01,  5.41888714e-01, ...,\n",
              "           5.06782904e-04, -4.40992355e-01,  1.21973813e-01],\n",
              "         [ 1.22988574e-01, -2.83345044e-01,  2.07830191e-01, ...,\n",
              "           6.40673876e-01, -4.43589211e-01,  3.09753478e-01],\n",
              "         ...,\n",
              "         [ 9.85538661e-02, -3.27361763e-01, -1.34624839e-01, ...,\n",
              "           6.45477772e-01, -3.26398134e-01, -1.30824864e-01],\n",
              "         [-4.96223941e-02, -4.16915178e-01, -9.67406631e-02, ...,\n",
              "           9.05962847e-03, -7.47699320e-01,  5.63223064e-01],\n",
              "         [ 4.59962666e-01, -2.10708931e-01,  4.46035743e-01, ...,\n",
              "           2.68225253e-01, -1.50929570e-01,  8.78290758e-02]]],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ctjq2PrGPuj"
      },
      "source": [
        "##### Bert Layer as Embedding Model: \n",
        "1. Have 3 differnt cnn filter of size 2,3,4\n",
        "2. Take max concatnate all\n",
        "3. Use BERT Embedding as  Layer after the last dense layer \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjks55flElvW"
      },
      "source": [
        "#Lets create a class for our model and it inherits from tf.keras.Model\n",
        "class DCNNBertEmbedding(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "               #  vocab_size,  not needed\n",
        "               #  emb_dim=128, not needed\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "               #  training=False, not needed\n",
        "                 name=\"dcnnembed\"):\n",
        "        super(DCNNBertEmbedding, self).__init__(name=name)\n",
        "\n",
        "#insted of creating tf.keras.layers.embedding we call keras layer form hub for the url - to use bert layer (base version)\n",
        "#trainable=False becasue we dont want to fine tune bert and use bert layer in frozen way .\n",
        "        self.bert_layer = hub.KerasLayer(\n",
        "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "            trainable=False)\n",
        "        \n",
        "        # self.embedding = layers.Embedding(vocab_size,    not needed\n",
        "        #                                   emb_dim)       not needed\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "#funciton to call embedder using bert . Input contain 3 different types of tokens. \n",
        "#we need to access them  using all batches \n",
        "#(all_tokens[:] ,\n",
        "#alltokens[]:, 0)- ids)\n",
        "#alltokens[]:, 1)- mask)\n",
        "#alltokens[]:, 2)- segments)\n",
        "#alltokens[:,x, :)- all values everything else)\n",
        "#Refer to cell below modeling example we ran .------->\n",
        "#Return: -, -one vector used to represent whole sentence ( used for classification tasks)\n",
        "#      : embs - representation of words/tokens individually - which we need only second part \n",
        "    def embed_with_bert(self, all_tokens):\n",
        "      _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
        "                                all_tokens[:, 1, :],\n",
        "                                all_tokens[:, 2, :]])\n",
        "      return embs\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embed_with_bert(inputs)\n",
        "        print(x.shape)\n",
        "        x_1 = self.bigram(x) # batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
        "        x_2 = self.trigram(x) # batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
        "        x_3 = self.fourgram(x) # batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5sRhmYePLiY"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6KXensuPPDM"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3JGfpK-PSIy"
      },
      "source": [
        "# Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "#             emb_dim=EMB_DIM,\n",
        "#             nb_filters=NB_FILTERS,\n",
        "#             FFN_units=FFN_UNITS,\n",
        "#             nb_classes=NB_CLASSES,\n",
        "#             dropout_rate=DROPOUT_RATE)\n",
        "Dcnn = DCNNBertEmbedding(nb_filters=NB_FILTERS,\n",
        "                         FFN_units=FFN_UNITS,\n",
        "                         nb_classes=NB_CLASSES,\n",
        "                         dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeYIDTiuPUQj"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRHxDleAPWsS"
      },
      "source": [
        "checkpoint_path = \"./drive/MyDrive/UOH/stanford-twitter/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFsrNY1_Pupw"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-_8BSSwPvsr",
        "outputId": "c4bec68d-3fbb-486b-b171-02ce9beb3e14"
      },
      "source": [
        "Dcnn.fit(train_dataset,epochs=NB_EPOCHS,callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "(None, None, 768)\n",
            "(None, None, 768)\n",
            "223/223 [==============================] - 81s 182ms/step - loss: 0.7471 - accuracy: 0.5452\n",
            "Checkpoint saved at ./drive/MyDrive/UOH/stanford-twitter/.\n",
            "Epoch 2/5\n",
            "223/223 [==============================] - 28s 125ms/step - loss: 0.6380 - accuracy: 0.6331\n",
            "Checkpoint saved at ./drive/MyDrive/UOH/stanford-twitter/.\n",
            "Epoch 3/5\n",
            "223/223 [==============================] - 28s 124ms/step - loss: 0.5723 - accuracy: 0.6882\n",
            "Checkpoint saved at ./drive/MyDrive/UOH/stanford-twitter/.\n",
            "Epoch 4/5\n",
            "223/223 [==============================] - 28s 123ms/step - loss: 0.4553 - accuracy: 0.7808\n",
            "Checkpoint saved at ./drive/MyDrive/UOH/stanford-twitter/.\n",
            "Epoch 5/5\n",
            "223/223 [==============================] - 28s 124ms/step - loss: 0.3371 - accuracy: 0.8474\n",
            "Checkpoint saved at ./drive/MyDrive/UOH/stanford-twitter/.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1289fbf390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfEvi3MUPyao"
      },
      "source": [
        ""
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGLEulq0P40d"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHmvX9AmP7Bo",
        "outputId": "82bbbf93-da08-4cf1-fff9-cb633d58b01b"
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 768)\n",
            "24/24 [==============================] - 4s 69ms/step - loss: 0.8538 - accuracy: 0.6276\n",
            "[0.853786289691925, 0.6276041865348816]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQWM7icPP-Yr"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "    tokens = encode_sentence(sentence)\n",
        "\n",
        "    input_ids = get_ids(tokens)\n",
        "    input_mask = get_mask(tokens)\n",
        "    segment_ids = get_segments(tokens)\n",
        "\n",
        "    inputs = tf.stack(\n",
        "        [tf.cast(input_ids, dtype=tf.int32),\n",
        "         tf.cast(input_mask, dtype=tf.int32),\n",
        "         tf.cast(segment_ids, dtype=tf.int32)],\n",
        "         axis=0)\n",
        "    \n",
        "    inputs = tf.expand_dims(inputs, 0) # simulates a batch\n",
        "\n",
        "    output = Dcnn(inputs, training=False)\n",
        "\n",
        "    sentiment = math.floor(output*2)\n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(\"Ouput of the model: {}\\nPredicted sentiment: negative.\".format(output))\n",
        "    elif sentiment == 1:\n",
        "        print(\"Ouput of the model: {}\\nPredicted sentiment: positive.\".format(output))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRVp3hf4QCf6",
        "outputId": "4a1d0f47-6dcc-426f-82d0-4eb854307486"
      },
      "source": [
        "get_prediction(\"Yes it took a long time but I did it\")\n",
        "get_prediction(\"Finally I was able to do it myself\")\n",
        "get_prediction(\"Yes I was able to do it with little help\")\n",
        "get_prediction(\"Do you really think that I did this mistake\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 12, 768)\n",
            "Ouput of the model: [[0.05795545]]\n",
            "Predicted sentiment: negative.\n",
            "(1, 11, 768)\n",
            "Ouput of the model: [[0.03170111]]\n",
            "Predicted sentiment: negative.\n",
            "(1, 12, 768)\n",
            "Ouput of the model: [[0.02811372]]\n",
            "Predicted sentiment: negative.\n",
            "(1, 12, 768)\n",
            "Ouput of the model: [[0.03635205]]\n",
            "Predicted sentiment: negative.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTYVgAaPRRbs",
        "outputId": "cab4241b-27dd-4a32-af20-1c0c449e9739"
      },
      "source": [
        "get_prediction(\"I'm sad to see these results\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10, 768)\n",
            "Ouput of the model: [[0.06537941]]\n",
            "Predicted sentiment: negative.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTxqKjGMUmQr",
        "outputId": "9a0e97f2-c897-4abb-df1d-ea823724701b"
      },
      "source": [
        "get_prediction(\"This actor is a deception.\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f128ace3320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f128ace3320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 9, 768)\n",
            "Ouput of the model: [[0.56446403]]\n",
            "Predicted sentiment: positive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b53vswuqU7N9",
        "outputId": "9ea820c0-e844-4719-cede-14718091ee5d"
      },
      "source": [
        "get_prediction(\"so disappointed to see the model fails\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 12, 768)\n",
            "Ouput of the model: [[0.39834484]]\n",
            "Predicted sentiment: negative.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd-1fJV9Wy4K",
        "outputId": "bca51390-f7f1-4775-dcf7-48826ae2e45c"
      },
      "source": [
        "get_prediction(\"so Happy to see the model works as expected\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 11, 768)\n",
            "Ouput of the model: [[0.6160313]]\n",
            "Predicted sentiment: positive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpLVNexoW3S4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
